{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from shared.constants import DatasetPath"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATASET = DatasetPath('DBLP-V3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/22 00:57:31 WARN Utils: Your hostname, megatron resolves to a loopback address: 127.0.1.1; using 192.168.1.89 instead (on interface enp7s0)\n",
      "22/01/22 00:57:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/22 00:57:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(f'{DATASET}')\n",
    "         .config('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "         .config(\"spark.executor.memory\", \"8g\")\n",
    "         .config(\"spark.driver.memory\", \"8g\")\n",
    "         .config(\"spark.memory.offHeap.enabled\", True)\n",
    "         .config(\"spark.memory.offHeap.size\", \"16g\")\n",
    "         .getOrCreate())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(value=['1632442', '#*OQL[C++]: Extending C++ with an Object Query Capability.', '#@José A. Blakeley', '#t1995', '#cModern Database Systems', '#index0']),\n Row(value=['#*Transaction Management in Multidatabase Systems.', '#@Yuri Breitbart,Hector Garcia-Molina,Abraham Silberschatz', '#t1995', '#cModern Database Systems', '#index1']),\n Row(value=['#*Overview of the ADDS System.', '#@Yuri Breitbart,Tom C. Reyes', '#t1995', '#cModern Database Systems', '#index2']),\n Row(value=['#*Multimedia Information Systems: Issues and Approaches.', '#@Stavros Christodoulakis,Leonidas Koveos', '#t1995', '#cModern Database Systems', '#index3']),\n Row(value=['#*Active Database Systems.', '#@Umeshwar Dayal,Eric N. Hanson,Jennifer Widom', '#t1995', '#cModern Database Systems', '#index4', '#%995520']),\n Row(value=['#*Where Object-Oriented DBMSs Should Do Better: A Critique Based on Early Experiences.', '#@Angelika Kotz Dittrich,Klaus R. Dittrich', '#t1995', '#cModern Database Systems', '#index5']),\n Row(value=['#*Distributed Databases.', '#@Hector Garcia-Molina,Meichun Hsu', '#t1995', '#cModern Database Systems', '#index6']),\n Row(value=['#*An Object-Oriented DBMS War Story: Developing a Genome Mapping Database in C++.', '#@Nathan Goodman', '#t1995', '#cModern Database Systems', '#index7']),\n Row(value=['#*Cooperative Transactions for Multiuser Environments.', '#@Gail E. Kaiser', '#t1995', '#cModern Database Systems', '#index8']),\n Row(value=['#*Schema Architecture of the UniSQL/M Multidatabase System', '#@William Kelley,Sunit K. Gala,Won Kim,Tom C. Reyes,Bruce Graham', '#t1995', '#cModern Database Systems', '#index9'])]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.text(DATASET.raw_str('DBLPOnlyCitationOct19.txt'), wholetext=False, lineSep='\\n\\n')\n",
    "        .withColumn('value', F.split(F.col('value'), '\\n'))\n",
    ")\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(title='OQL[C++]: Extending C++ with an Object Query Capability.', authors=['José A. Blakeley'], year=1995, venue='Modern Database Systems', index=0, references=[], abstract=None),\n Row(title='Transaction Management in Multidatabase Systems.', authors=['Yuri Breitbart', 'Hector Garcia-Molina', 'Abraham Silberschatz'], year=1995, venue='Modern Database Systems', index=1, references=[], abstract=None),\n Row(title='Overview of the ADDS System.', authors=['Yuri Breitbart', 'Tom C. Reyes'], year=1995, venue='Modern Database Systems', index=2, references=[], abstract=None),\n Row(title='Multimedia Information Systems: Issues and Approaches.', authors=['Stavros Christodoulakis', 'Leonidas Koveos'], year=1995, venue='Modern Database Systems', index=3, references=[], abstract=None),\n Row(title='Active Database Systems.', authors=['Umeshwar Dayal', 'Eric N. Hanson', 'Jennifer Widom'], year=1995, venue='Modern Database Systems', index=4, references=['995520'], abstract=None)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('title', T.StringType(), True),\n",
    "    T.StructField('authors', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('year', T.IntegerType(), True),\n",
    "    T.StructField('venue', T.StringType(), True),\n",
    "    T.StructField('index', T.IntegerType(), True),\n",
    "    T.StructField('references', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('abstract', T.StringType(), True),\n",
    "])\n",
    "\n",
    "@F.udf(returnType=schema)\n",
    "def parse_citation(lines):\n",
    "    result = {\n",
    "        'title': None,\n",
    "        'authors': [],\n",
    "        'year': None,\n",
    "        'venue': None,\n",
    "        'index': None,\n",
    "        'references': [],\n",
    "        'abstract': None,\n",
    "    }\n",
    "    for line in lines:\n",
    "        if line.startswith('#*'):\n",
    "            result['title'] = line[2:].strip()\n",
    "        elif line.startswith('#@'):\n",
    "            result['authors'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#t'):\n",
    "            result['year'] = int(line[2:].strip())\n",
    "        elif line.startswith('#c'):\n",
    "            result['venue'] = line[2:].strip()\n",
    "        elif line.startswith('#index'):\n",
    "            result['index'] = int(line[6:].strip())\n",
    "        elif line.startswith('#%'):\n",
    "            result['references'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#!'):\n",
    "            result['abstract'] = line[2:].strip()\n",
    "    return result\n",
    "\n",
    "df_papers = df.select(\n",
    "    parse_citation(F.col('value')).alias('parsed_citation')\n",
    ").select('parsed_citation.*').cache()\n",
    "df_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(name=' Aihua Bao', id=' Aihua Bao'),\n Row(name=' C.D.', id=' C.D.'),\n Row(name=' D.F.', id=' D.F.'),\n Row(name=' F.F.', id=' F.F.'),\n Row(name=' G.A.', id=' G.A.')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_authors = (\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('name'),\n",
    "    ).withColumn('id', F.col('name')).filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_authors.count())\n",
    "df_nodes_authors.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7707\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id='10th Anniversary Colloquium of UNU/IIST', name='10th Anniversary Colloquium of UNU/IIST'),\n Row(id='13th Annual Symposium on Switching and Automata Theory', name='13th Annual Symposium on Switching and Automata Theory'),\n Row(id='14th Annual Symposium on Switching and Automata Theory', name='14th Annual Symposium on Switching and Automata Theory'),\n Row(id='15. WLP', name='15. WLP'),\n Row(id='15th Annual Symposium on Switching and Automata Theory', name='15th Annual Symposium on Switching and Automata Theory')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_venues = (\n",
    "    df_papers.select(\n",
    "        F.col('venue').alias('id'),\n",
    "        F.col('venue').alias('name'),\n",
    "    ).filter(\"id != ''\").filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_venues.count())\n",
    "df_nodes_venues.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id=31, title='The Changing Database Standards Landscape.', authors=['Craig W. Thompson'], venue='Modern Database Systems', year=1995, abstract=None, timestamp=datetime.datetime(1995, 1, 1, 0, 0)),\n Row(id=34, title='Version Control in an Object-Oriented Architecture.', authors=['Anders Björnerstedt', 'Christer Hulten'], venue='Object-Oriented Concepts, Databases, and Applications', year=1989, abstract=None, timestamp=datetime.datetime(1989, 1, 1, 0, 0)),\n Row(id=53, title='Pogo: A Declarative Representation System for Graphics.', authors=['Mark A. Tarlton', 'P. Nong Tarlton'], venue='Object-Oriented Concepts, Databases, and Applications', year=1989, abstract=None, timestamp=datetime.datetime(1989, 1, 1, 0, 0)),\n Row(id=65, title='Database Design (Introduction to Section 6).', authors=['Michael Stonebraker'], venue='The INGRES Papers', year=1986, abstract=None, timestamp=datetime.datetime(1986, 1, 1, 0, 0)),\n Row(id=78, title='Algorithms', authors=['Robert Sedgewick'], venue='', year=1983, abstract='This presentation is a tutorial on AutoView, an AutoMod extension package that recreates model animation according to a user-defined script. AutoView allows users to restart animation and move back and forth in time and 3-D space. Animation is created using text files generated from an AutoMod simulation model. By creating a user-defined camera description file, animation can take place that allows for panning from one view to another, as well as for attaching the camera to a simulated load or vehicle and traveling with that entity during portions of the animation. The animation is provided at an enhanced response time because it does not have the logical and statistical processes of AutoMod (which can slow animation). This tutorial demonstrates several animation scripts previously constructed with AutoView, discusses the creation of AutoView files from AutoMod, and describes the development of a camera description file.', timestamp=datetime.datetime(1983, 1, 1, 0, 0))]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers = (\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('id'),\n",
    "        'title',\n",
    "        'authors',\n",
    "        'venue',\n",
    "        'year',\n",
    "        'abstract',\n",
    "        F.to_timestamp(F.col('year').cast('string'), 'yyyy').alias('timestamp')\n",
    "    ).filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_papers.count())\n",
    "df_nodes_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_node_ids = (\n",
    "    df_nodes_authors.select('id')\n",
    "        .union(df_nodes_venues.select('id'))\n",
    "        .union(df_nodes_papers.select('id'))\n",
    "        .distinct()\n",
    ")\n",
    "\n",
    "def filter_node_ids(df):\n",
    "    return df.join(\n",
    "        df_node_ids,\n",
    "        F.col('src') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop(\n",
    "        'id'\n",
    "    ).join(\n",
    "        df_node_ids,\n",
    "        F.col('dst') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop('id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src='Craig W. Thompson', dst=31),\n Row(src='Anders Björnerstedt', dst=34),\n Row(src='Christer Hulten', dst=34),\n Row(src='P. Nong Tarlton', dst=53),\n Row(src='Mark A. Tarlton', dst=53)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_authored = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('src'),\n",
    "        F.col('index').alias('dst'),\n",
    "    ).distinct()\n",
    ")\n",
    "print(df_edges_authored.count())\n",
    "df_edges_authored.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src=18942, dst='ACISP'),\n Row(src=18944, dst='ACISP'),\n Row(src=18956, dst='ACISP'),\n Row(src=18966, dst='ACISP'),\n Row(src=18979, dst='ACISP')]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_published_in = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.col('venue').alias('dst'),\n",
    "    ).filter(\"dst != ''\").distinct()\n",
    ")\n",
    "print(df_edges_published_in.count())\n",
    "df_edges_published_in.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src=1113552, dst=28),\n Row(src=846493, dst=28),\n Row(src=183947, dst=28),\n Row(src=95913, dst=28),\n Row(src=176164, dst=28)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_cited = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.explode(F.col('references')).alias('dst'),\n",
    "    )\n",
    "        .withColumn('dst', F.col('dst').cast('int'))\n",
    "        .distinct()\n",
    "\n",
    ")\n",
    "print(df_edges_cited.count())\n",
    "df_edges_cited.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_authors.write.parquet(DATASET.processed_str('nodes_Author'), mode='overwrite')\n",
    "df_nodes_venues.write.parquet(DATASET.processed_str('nodes_Venue'), mode='overwrite')\n",
    "df_nodes_papers.write.parquet(DATASET.processed_str('nodes_Paper'), mode='overwrite')\n",
    "\n",
    "df_edges_authored.write.parquet(DATASET.processed_str('edges_AUTHORED'), mode='overwrite')\n",
    "df_edges_published_in.write.parquet(DATASET.processed_str('edges_PUBLISHED_IN'), mode='overwrite')\n",
    "df_edges_cited.write.parquet(DATASET.processed_str('edges_CITED'), mode='overwrite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-22 00:59:12,920][/dd_volume/Development/Python/Thesis/code/datasets/datasets/build_schema.py][DEBUG] Merging old schema for DBLP-V3\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetSchema(name='DBLP-V3', prefix='DBLP_V3', database='DBLP-V3', description='None', nodes=[NodeSchema(path='data/processed/DBLP-V3/nodes_Author', properties=[Property(name='name', type='string', ignore=False, label=True, timestamp=False), Property(name='id', type='string', ignore=False, label=False, timestamp=False)], label='Author', interaction=False), NodeSchema(path='data/processed/DBLP-V3/nodes_Venue', properties=[Property(name='id', type='string', ignore=False, label=False, timestamp=False), Property(name='name', type='string', ignore=False, label=True, timestamp=False)], label='Venue', interaction=False), NodeSchema(path='data/processed/DBLP-V3/nodes_Paper', properties=[Property(name='id', type='int', ignore=False, label=False, timestamp=False), Property(name='title', type='string', ignore=False, label=True, timestamp=False), Property(name='authors', type='string[]', ignore=False, label=False, timestamp=False), Property(name='venue', type='string', ignore=False, label=False, timestamp=False), Property(name='year', type='int', ignore=False, label=False, timestamp=False), Property(name='abstract', type='string', ignore=False, label=False, timestamp=False), Property(name='timestamp', type='datetime', ignore=False, label=False, timestamp=True)], label='Paper', interaction=False)], edges=[EdgeSchema(path='data/processed/DBLP-V3/edges_AUTHORED', properties=[Property(name='src', type='string', ignore=False, label=False, timestamp=False), Property(name='dst', type='int', ignore=False, label=False, timestamp=False)], type='AUTHORED', source='Author', target='Paper', directed=True, interaction=False), EdgeSchema(path='data/processed/DBLP-V3/edges_PUBLISHED_IN', properties=[Property(name='src', type='int', ignore=False, label=False, timestamp=False), Property(name='dst', type='string', ignore=False, label=False, timestamp=False)], type='PUBLISHED_IN', source='Paper', target='Venue', directed=True, interaction=False), EdgeSchema(path='data/processed/DBLP-V3/edges_CITED', properties=[Property(name='src', type='int', ignore=False, label=False, timestamp=False), Property(name='dst', type='int', ignore=False, label=False, timestamp=False)], type='CITED', source='Paper', target='Paper', directed=True, interaction=False)], ground_truth=None, versions={})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.build_schema import build_schema\n",
    "\n",
    "build_schema(\n",
    "    spark,\n",
    "    name=str(DATASET),\n",
    "    nodes=[\n",
    "        ('Author', DATASET.processed_str('nodes_Author')),\n",
    "        ('Venue', DATASET.processed_str('nodes_Venue')),\n",
    "        ('Paper', DATASET.processed_str('nodes_Paper')),\n",
    "    ],\n",
    "    edges=[\n",
    "        ('Authored', 'Author', 'Paper', DATASET.processed_str('edges_AUTHORED')),\n",
    "        ('PublishedIn', 'Paper', 'Venue', DATASET.processed_str('edges_PUBLISHED_IN')),\n",
    "        ('Cited', 'Paper', 'Paper', DATASET.processed_str('edges_CITED')),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ground truth communities\n",
    "Using same methodology as in:\n",
    "\n",
    "J. Yang and J. Leskovec, “Defining and evaluating network communities based on ground-truth,” in Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics, New York, NY, USA, Aug. 2012, pp. 1–8. doi: 10.1145/2350190.2350193."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(venue='Advances in Object-Oriented Data Modeling', count=13), Row(venue='Handbook on Ontologies', count=33), Row(venue='CARS', count=949), Row(venue='CSR', count=223), Row(venue='Workshop on Database Issues for Data Visualization', count=34), Row(venue='EASSS', count=21), Row(venue='KWEPSY', count=31), Row(venue='GIS', count=368), Row(venue='International Conference on Internet Computing', count=847), Row(venue='ICECCS', count=570), Row(venue='Designing Smart Homes', count=11), Row(venue='ICPR (3)', count=796), Row(venue='IHIS', count=13), Row(venue='BIOKDD', count=52), Row(venue='Multimedia Information Retrieval', count=341), Row(venue='WiOpt', count=169), Row(venue='QoSA', count=76), Row(venue='GRAPP (GM/R)', count=46), Row(venue='SCW', count=27), Row(venue='ITSL', count=20), Row(venue='Empirical Software Engineering', count=302), Row(venue='Formal Asp. Comput.', count=573), Row(venue='Int. J. Cooperative Inf. Syst.', count=344), Row(venue='Parts, Hybrids, and Packaging, IEEE Transactions on', count=342), Row(venue='The EBU-SMPTE Task Force: Building an Infrastructure for Managing Compressed Video Systems (Ref. No: 1997/382), IEE Colloquium on', count=4), Row(venue='Intelligent Control, 2002. Proceedings of the 2002 IEEE International Symposium on', count=158), Row(venue='ECAI Workshop on Ontology Learning', count=13), Row(venue='ESWC (1)', count=30), Row(venue='PAKDD (2)', count=49), Row(venue='ADBIS-DASFAA', count=35), Row(venue='CAiSE', count=804), Row(venue='Constructivity in Computer Science', count=17), Row(venue='Multiobjective Optimization', count=17), Row(venue='Digital Image Processing Systems', count=8), Row(venue='Haifa Verification Conference', count=80), Row(venue='ICSR', count=213), Row(venue='Mobility Management & Wireless Access Protocols', count=23), Row(venue='OBPDC', count=19), Row(venue='QoS-IP', count=134), Row(venue='SASN', count=63), Row(venue='SIGSOFT FSE', count=228), Row(venue='LMO', count=135), Row(venue='WSTST', count=137), Row(venue='ACM SIGMOD Digital Review', count=141), Row(venue='Bulletin of the EATCS', count=700), Row(venue='JETC', count=87), Row(venue='IEEE Trans. Knowl. Data Eng.', count=2061), Row(venue='Virtual Reality', count=210), Row(venue='IJSNet', count=73), Row(venue='ICE-B', count=217), Row(venue='Antennas and Propagation Society International Symposium, 1976', count=139), Row(venue='Distributed Computing Systems, 2003. Proceedings. 23rd International Conference on', count=75), Row(venue='Southern Tier Technical Conference, 1987. Proceedings of the 1987 IEEE', count=37), Row(venue='LCS, IEEE', count=32), Row(venue='Storage and Retrieval for Media Databases', count=210), Row(venue='SIAM J. Control and Optimization', count=1178), Row(venue='Performance Modeling, Loss Networks, and Statistical Multiplexing', count=1), Row(venue='Unified Modeling Language: Systems Analysis, Design and Development Issues', count=16), Row(venue='IEEE SCC', count=613), Row(venue='AMiRE', count=58), Row(venue='Banff Higher Order Workshop', count=6), Row(venue='FAABS', count=94), Row(venue='WHC', count=384), Row(venue='I3E', count=284), Row(venue='IAT Workshops', count=143), Row(venue='ICMLA', count=632), Row(venue='eTRAIN', count=42), Row(venue='Geometric Modeling', count=18), Row(venue='Information Systems Perspectives and Challenges in the Context of Globalization', count=30), Row(venue='IOLTW', count=138), Row(venue='ISMDA', count=125), Row(venue='MMM', count=494), Row(venue='Hardware Specification, Verification and Synthesis', count=20), Row(venue='Computer Architecture for Non-Numeric Processing', count=47), Row(venue='SPLC', count=307), Row(venue='PSIVT', count=313), Row(venue='OWLED', count=182), Row(venue='CEE-SET', count=24), Row(venue='IJPEDS', count=92), Row(venue='Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on', count=187), Row(venue='Image Processing and Multimedia - Collaborative Projects and Funding Opportunities (Ref. No: 1997/364), IEE Colloquium on', count=1), Row(venue='IWRT', count=48), Row(venue='Agents', count=520), Row(venue='AINA Workshops', count=675), Row(venue='ASST', count=128), Row(venue='CAiSE Workshops', count=45), Row(venue='ICTCS', count=113), Row(venue='ISPAN', count=713), Row(venue='KESE', count=18), Row(venue='Mobile HCI', count=624), Row(venue='Neural Networks: Tricks of the Trade', count=24), Row(venue='HUG', count=41), Row(venue='TrustBus', count=179), Row(venue='Web3D', count=241), Row(venue='ICICIC (1)', count=180), Row(venue='ICIW', count=292), Row(venue='Ann. Software Eng.', count=197), Row(venue='Industrial Management and Data Systems', count=645), Row(venue='Journal of Quantitative Linguistics', count=306), Row(venue='CIKM-SWSM', count=10)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(df_nodes_papers.groupby('venue').count().head(100))\n",
    "print(df_nodes_papers.filter(F.col('venue').isNull()).head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "2705"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers.groupby('venue').count().filter('count < 10').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nodes_papers.groupby('venue').count().filter('count > 100').head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cant compute ground truth communities. Venue is actually a journal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}