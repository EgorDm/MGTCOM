{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from shared.constants import DatasetPath"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATASET = DatasetPath('DBLP-V3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/19 20:38:16 WARN Utils: Your hostname, megatron resolves to a loopback address: 127.0.1.1; using 192.168.1.89 instead (on interface enp7s0)\n",
      "22/01/19 20:38:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/19 20:38:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/19 20:38:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/01/19 20:38:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(f'{DATASET}')\n",
    "         .config('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "         .config(\"spark.executor.memory\", \"8g\")\n",
    "         .config(\"spark.driver.memory\", \"8g\")\n",
    "         .config(\"spark.memory.offHeap.enabled\", True)\n",
    "         .config(\"spark.memory.offHeap.size\", \"16g\")\n",
    "         .getOrCreate())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(value=['1632442', '#*OQL[C++]: Extending C++ with an Object Query Capability.', '#@José A. Blakeley', '#t1995', '#cModern Database Systems', '#index0']),\n Row(value=['#*Transaction Management in Multidatabase Systems.', '#@Yuri Breitbart,Hector Garcia-Molina,Abraham Silberschatz', '#t1995', '#cModern Database Systems', '#index1']),\n Row(value=['#*Overview of the ADDS System.', '#@Yuri Breitbart,Tom C. Reyes', '#t1995', '#cModern Database Systems', '#index2']),\n Row(value=['#*Multimedia Information Systems: Issues and Approaches.', '#@Stavros Christodoulakis,Leonidas Koveos', '#t1995', '#cModern Database Systems', '#index3']),\n Row(value=['#*Active Database Systems.', '#@Umeshwar Dayal,Eric N. Hanson,Jennifer Widom', '#t1995', '#cModern Database Systems', '#index4', '#%995520']),\n Row(value=['#*Where Object-Oriented DBMSs Should Do Better: A Critique Based on Early Experiences.', '#@Angelika Kotz Dittrich,Klaus R. Dittrich', '#t1995', '#cModern Database Systems', '#index5']),\n Row(value=['#*Distributed Databases.', '#@Hector Garcia-Molina,Meichun Hsu', '#t1995', '#cModern Database Systems', '#index6']),\n Row(value=['#*An Object-Oriented DBMS War Story: Developing a Genome Mapping Database in C++.', '#@Nathan Goodman', '#t1995', '#cModern Database Systems', '#index7']),\n Row(value=['#*Cooperative Transactions for Multiuser Environments.', '#@Gail E. Kaiser', '#t1995', '#cModern Database Systems', '#index8']),\n Row(value=['#*Schema Architecture of the UniSQL/M Multidatabase System', '#@William Kelley,Sunit K. Gala,Won Kim,Tom C. Reyes,Bruce Graham', '#t1995', '#cModern Database Systems', '#index9'])]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.text(DATASET.raw_str('DBLPOnlyCitationOct19.txt'), wholetext=False, lineSep='\\n\\n')\n",
    "        .withColumn('value', F.split(F.col('value'), '\\n'))\n",
    ")\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(title='OQL[C++]: Extending C++ with an Object Query Capability.', authors=['José A. Blakeley'], year=1995, venue='Modern Database Systems', index=0, references=[], abstract=None),\n Row(title='Transaction Management in Multidatabase Systems.', authors=['Yuri Breitbart', 'Hector Garcia-Molina', 'Abraham Silberschatz'], year=1995, venue='Modern Database Systems', index=1, references=[], abstract=None),\n Row(title='Overview of the ADDS System.', authors=['Yuri Breitbart', 'Tom C. Reyes'], year=1995, venue='Modern Database Systems', index=2, references=[], abstract=None),\n Row(title='Multimedia Information Systems: Issues and Approaches.', authors=['Stavros Christodoulakis', 'Leonidas Koveos'], year=1995, venue='Modern Database Systems', index=3, references=[], abstract=None),\n Row(title='Active Database Systems.', authors=['Umeshwar Dayal', 'Eric N. Hanson', 'Jennifer Widom'], year=1995, venue='Modern Database Systems', index=4, references=['995520'], abstract=None)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('title', T.StringType(), True),\n",
    "    T.StructField('authors', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('year', T.IntegerType(), True),\n",
    "    T.StructField('venue', T.StringType(), True),\n",
    "    T.StructField('index', T.IntegerType(), True),\n",
    "    T.StructField('references', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('abstract', T.StringType(), True),\n",
    "])\n",
    "\n",
    "@F.udf(returnType=schema)\n",
    "def parse_citation(lines):\n",
    "    result = {\n",
    "        'title': None,\n",
    "        'authors': [],\n",
    "        'year': None,\n",
    "        'venue': None,\n",
    "        'index': None,\n",
    "        'references': [],\n",
    "        'abstract': None,\n",
    "    }\n",
    "    for line in lines:\n",
    "        if line.startswith('#*'):\n",
    "            result['title'] = line[2:].strip()\n",
    "        elif line.startswith('#@'):\n",
    "            result['authors'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#t'):\n",
    "            result['year'] = int(line[2:].strip())\n",
    "        elif line.startswith('#c'):\n",
    "            result['venue'] = line[2:].strip()\n",
    "        elif line.startswith('#index'):\n",
    "            result['index'] = int(line[6:].strip())\n",
    "        elif line.startswith('#%'):\n",
    "            result['references'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#!'):\n",
    "            result['abstract'] = line[2:].strip()\n",
    "    return result\n",
    "\n",
    "df_papers = df.select(\n",
    "    parse_citation(F.col('value')).alias('parsed_citation')\n",
    ").select('parsed_citation.*').cache()\n",
    "df_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(name=' Aihua Bao', id=' Aihua Bao'),\n Row(name=' C.D.', id=' C.D.'),\n Row(name=' D.F.', id=' D.F.'),\n Row(name=' F.F.', id=' F.F.'),\n Row(name=' G.A.', id=' G.A.')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_authors = (\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('name'),\n",
    "    ).withColumn('id', F.col('name')).filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_authors.count())\n",
    "df_nodes_authors.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7707\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id='10th Anniversary Colloquium of UNU/IIST', name='10th Anniversary Colloquium of UNU/IIST'),\n Row(id='13th Annual Symposium on Switching and Automata Theory', name='13th Annual Symposium on Switching and Automata Theory'),\n Row(id='14th Annual Symposium on Switching and Automata Theory', name='14th Annual Symposium on Switching and Automata Theory'),\n Row(id='15. WLP', name='15. WLP'),\n Row(id='15th Annual Symposium on Switching and Automata Theory', name='15th Annual Symposium on Switching and Automata Theory')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_venues = (\n",
    "    df_papers.select(\n",
    "        F.col('venue').alias('id'),\n",
    "        F.col('venue').alias('name'),\n",
    "    ).filter(\"id != ''\").filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_venues.count())\n",
    "df_nodes_venues.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id=31, title='The Changing Database Standards Landscape.', authors=['Craig W. Thompson'], venue='Modern Database Systems', year=1995, abstract=None, timestamp=datetime.datetime(1995, 1, 1, 0, 0)),\n Row(id=34, title='Version Control in an Object-Oriented Architecture.', authors=['Anders Björnerstedt', 'Christer Hulten'], venue='Object-Oriented Concepts, Databases, and Applications', year=1989, abstract=None, timestamp=datetime.datetime(1989, 1, 1, 0, 0)),\n Row(id=53, title='Pogo: A Declarative Representation System for Graphics.', authors=['Mark A. Tarlton', 'P. Nong Tarlton'], venue='Object-Oriented Concepts, Databases, and Applications', year=1989, abstract=None, timestamp=datetime.datetime(1989, 1, 1, 0, 0)),\n Row(id=65, title='Database Design (Introduction to Section 6).', authors=['Michael Stonebraker'], venue='The INGRES Papers', year=1986, abstract=None, timestamp=datetime.datetime(1986, 1, 1, 0, 0)),\n Row(id=78, title='Algorithms', authors=['Robert Sedgewick'], venue='', year=1983, abstract='This presentation is a tutorial on AutoView, an AutoMod extension package that recreates model animation according to a user-defined script. AutoView allows users to restart animation and move back and forth in time and 3-D space. Animation is created using text files generated from an AutoMod simulation model. By creating a user-defined camera description file, animation can take place that allows for panning from one view to another, as well as for attaching the camera to a simulated load or vehicle and traveling with that entity during portions of the animation. The animation is provided at an enhanced response time because it does not have the logical and statistical processes of AutoMod (which can slow animation). This tutorial demonstrates several animation scripts previously constructed with AutoView, discusses the creation of AutoView files from AutoMod, and describes the development of a camera description file.', timestamp=datetime.datetime(1983, 1, 1, 0, 0))]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers = (\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('id'),\n",
    "        'title',\n",
    "        'authors',\n",
    "        'venue',\n",
    "        'year',\n",
    "        'abstract',\n",
    "        F.to_timestamp(F.col('year').cast('string'), 'yyyy').alias('timestamp')\n",
    "    ).filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_papers.count())\n",
    "df_nodes_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_node_ids = (\n",
    "    df_nodes_authors.select('id')\n",
    "        .union(df_nodes_venues.select('id'))\n",
    "        .union(df_nodes_papers.select('id'))\n",
    "        .distinct()\n",
    ")\n",
    "\n",
    "def filter_node_ids(df):\n",
    "    return df.join(\n",
    "        df_node_ids,\n",
    "        F.col('src') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop(\n",
    "        'id'\n",
    "    ).join(\n",
    "        df_node_ids,\n",
    "        F.col('dst') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop('id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src='Craig W. Thompson', dst=31),\n Row(src='Anders Björnerstedt', dst=34),\n Row(src='Christer Hulten', dst=34),\n Row(src='P. Nong Tarlton', dst=53),\n Row(src='Mark A. Tarlton', dst=53)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_authored = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('src'),\n",
    "        F.col('index').alias('dst'),\n",
    "    ).distinct()\n",
    ")\n",
    "print(df_edges_authored.count())\n",
    "df_edges_authored.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src=18942, dst='ACISP'),\n Row(src=18944, dst='ACISP'),\n Row(src=18956, dst='ACISP'),\n Row(src=18966, dst='ACISP'),\n Row(src=18979, dst='ACISP')]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_published_in = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.col('venue').alias('dst'),\n",
    "    ).filter(\"dst != ''\").distinct()\n",
    ")\n",
    "print(df_edges_published_in.count())\n",
    "df_edges_published_in.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src=1113552, dst=28),\n Row(src=846493, dst=28),\n Row(src=183947, dst=28),\n Row(src=95913, dst=28),\n Row(src=176164, dst=28)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_cited = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.explode(F.col('references')).alias('dst'),\n",
    "    )\n",
    "        .withColumn('dst', F.col('dst').cast('int'))\n",
    "        .distinct()\n",
    "\n",
    ")\n",
    "print(df_edges_cited.count())\n",
    "df_edges_cited.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_authors.write.parquet(DATASET.processed_str('nodes_Author'), mode='overwrite')\n",
    "df_nodes_venues.write.parquet(DATASET.processed_str('nodes_Venue'), mode='overwrite')\n",
    "df_nodes_papers.write.parquet(DATASET.processed_str('nodes_Paper'), mode='overwrite')\n",
    "\n",
    "df_edges_authored.write.parquet(DATASET.processed_str('edges_AUTHORED'), mode='overwrite')\n",
    "df_edges_published_in.write.parquet(DATASET.processed_str('edges_PUBLISHED_IN'), mode='overwrite')\n",
    "df_edges_cited.write.parquet(DATASET.processed_str('edges_CITED'), mode='overwrite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-19 20:40:15,284][/dd_volume/Development/Python/Thesis/code/datasets/datasets/build_schema.py][DEBUG] Merging old schema for DBLP-V3\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetSchema(name='DBLP-V3', prefix='DBLP_V3', database='DBLP-V3', description='None', nodes=[NodeSchema(path='data/processed/DBLP-V3/nodes_Author', properties=[Property(name='name', type='string', ignore=False, label=True, timestamp=False), Property(name='id', type='string', ignore=False, label=False, timestamp=False)], label='Author'), NodeSchema(path='data/processed/DBLP-V3/nodes_Venue', properties=[Property(name='id', type='string', ignore=False, label=False, timestamp=False), Property(name='name', type='string', ignore=False, label=True, timestamp=False)], label='Venue'), NodeSchema(path='data/processed/DBLP-V3/nodes_Paper', properties=[Property(name='id', type='int', ignore=False, label=False, timestamp=False), Property(name='title', type='string', ignore=False, label=True, timestamp=False), Property(name='authors', type='string[]', ignore=False, label=False, timestamp=False), Property(name='venue', type='string', ignore=False, label=False, timestamp=False), Property(name='year', type='int', ignore=False, label=False, timestamp=False), Property(name='abstract', type='string', ignore=False, label=False, timestamp=False), Property(name='timestamp', type='datetime', ignore=False, label=False, timestamp=False)], label='Paper')], edges=[EdgeSchema(path='data/processed/DBLP-V3/edges_AUTHORED', properties=[Property(name='src', type='string', ignore=False, label=False, timestamp=False), Property(name='dst', type='int', ignore=False, label=False, timestamp=False)], type='AUTHORED', source='Author', target='Paper', directed=True), EdgeSchema(path='data/processed/DBLP-V3/edges_PUBLISHED_IN', properties=[Property(name='src', type='int', ignore=False, label=False, timestamp=False), Property(name='dst', type='string', ignore=False, label=False, timestamp=False)], type='PUBLISHED_IN', source='Paper', target='Venue', directed=True), EdgeSchema(path='data/processed/DBLP-V3/edges_CITED', properties=[Property(name='src', type='int', ignore=False, label=False, timestamp=False), Property(name='dst', type='int', ignore=False, label=False, timestamp=False)], type='CITED', source='Paper', target='Paper', directed=True)])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.build_schema import build_schema\n",
    "\n",
    "build_schema(\n",
    "    spark,\n",
    "    name=str(DATASET),\n",
    "    nodes=[\n",
    "        ('Author', DATASET.processed_str('nodes_Author')),\n",
    "        ('Venue', DATASET.processed_str('nodes_Venue')),\n",
    "        ('Paper', DATASET.processed_str('nodes_Paper')),\n",
    "    ],\n",
    "    edges=[\n",
    "        ('Authored', 'Author', 'Paper', DATASET.processed_str('edges_AUTHORED')),\n",
    "        ('PublishedIn', 'Paper', 'Venue', DATASET.processed_str('edges_PUBLISHED_IN')),\n",
    "        ('Cited', 'Paper', 'Paper', DATASET.processed_str('edges_CITED')),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}