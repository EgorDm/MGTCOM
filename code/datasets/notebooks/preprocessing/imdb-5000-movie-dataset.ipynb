{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from shared.schema import DatasetSchema\n",
    "\n",
    "DATASET = DatasetSchema.load_schema('imdb-5000-movie-dataset')\n",
    "DATASET.save_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x3e07d849) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x3e07d849\n\tat org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)\n\tat org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:110)\n\tat org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:348)\n\tat org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:287)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:336)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:191)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:460)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[38;5;241m=\u001b[39m (\u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspark.sql.legacy.timeParserPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLEGACY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.executor.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m8g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.driver.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m8g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.memory.offHeap.enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.memory.offHeap.size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m16g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/sql/session.py:228\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/context.py:392\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/context.py:146\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    144\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/context.py:209\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/context.py:329\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, jconf):\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Initialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/py4j/java_gateway.py:1573\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1567\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1569\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1570\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1572\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1573\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1577\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x3e07d849) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x3e07d849\n\tat org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)\n\tat org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:110)\n\tat org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:348)\n\tat org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:287)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:336)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:191)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:460)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(f'{DATASET}')\n",
    "         .config('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "         .config(\"spark.executor.memory\", \"8g\")\n",
    "         .config(\"spark.driver.memory\", \"8g\")\n",
    "         .config(\"spark.memory.offHeap.enabled\", True)\n",
    "         .config(\"spark.memory.offHeap.size\", \"16g\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/22 22:23:41 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(color='Color', director_name='James Cameron', num_critic_for_reviews=723, duration=178, director_facebook_likes=0, actor_3_facebook_likes=855, actor_2_name='Joel David Moore', actor_1_facebook_likes=1000, gross=760505847, genres=['Action', 'Adventure', 'Fantasy', 'Sci-Fi'], actor_1_name='CCH Pounder', movie_title='Avatar\\xa0', num_voted_users=886204, cast_total_facebook_likes=4834, actor_3_name='Wes Studi', facenumber_in_poster=0, plot_keywords=['avatar', 'future', 'marine', 'native', 'paraplegic'], movie_imdb_link='http://www.imdb.com/title/tt0499549/?ref_=fn_tt_tt_1', num_user_for_reviews=3054, language='English', country='USA', content_rating='PG-13', budget=237000000, title_year=2009, actor_2_facebook_likes=936, imdb_score=7.9, aspect_ratio=1.78, movie_facebook_likes=33000, id='tt0499549'),\n",
       " Row(color='Color', director_name='Gore Verbinski', num_critic_for_reviews=302, duration=169, director_facebook_likes=563, actor_3_facebook_likes=1000, actor_2_name='Orlando Bloom', actor_1_facebook_likes=40000, gross=309404152, genres=['Action', 'Adventure', 'Fantasy'], actor_1_name='Johnny Depp', movie_title=\"Pirates of the Caribbean: At World's End\\xa0\", num_voted_users=471220, cast_total_facebook_likes=48350, actor_3_name='Jack Davenport', facenumber_in_poster=0, plot_keywords=['goddess', 'marriage ceremony', 'marriage proposal', 'pirate', 'singapore'], movie_imdb_link='http://www.imdb.com/title/tt0449088/?ref_=fn_tt_tt_1', num_user_for_reviews=1238, language='English', country='USA', content_rating='PG-13', budget=300000000, title_year=2007, actor_2_facebook_likes=5000, imdb_score=7.1, aspect_ratio=2.35, movie_facebook_likes=0, id='tt0449088'),\n",
       " Row(color='Color', director_name='Sam Mendes', num_critic_for_reviews=602, duration=148, director_facebook_likes=0, actor_3_facebook_likes=161, actor_2_name='Rory Kinnear', actor_1_facebook_likes=11000, gross=200074175, genres=['Action', 'Adventure', 'Thriller'], actor_1_name='Christoph Waltz', movie_title='Spectre\\xa0', num_voted_users=275868, cast_total_facebook_likes=11700, actor_3_name='Stephanie Sigman', facenumber_in_poster=1, plot_keywords=['bomb', 'espionage', 'sequel', 'spy', 'terrorist'], movie_imdb_link='http://www.imdb.com/title/tt2379713/?ref_=fn_tt_tt_1', num_user_for_reviews=994, language='English', country='UK', content_rating='PG-13', budget=245000000, title_year=2015, actor_2_facebook_likes=393, imdb_score=6.8, aspect_ratio=2.35, movie_facebook_likes=85000, id='tt2379713'),\n",
       " Row(color='Color', director_name='Christopher Nolan', num_critic_for_reviews=813, duration=164, director_facebook_likes=22000, actor_3_facebook_likes=23000, actor_2_name='Christian Bale', actor_1_facebook_likes=27000, gross=448130642, genres=['Action', 'Thriller'], actor_1_name='Tom Hardy', movie_title='The Dark Knight Rises\\xa0', num_voted_users=1144337, cast_total_facebook_likes=106759, actor_3_name='Joseph Gordon-Levitt', facenumber_in_poster=0, plot_keywords=['deception', 'imprisonment', 'lawlessness', 'police officer', 'terrorist plot'], movie_imdb_link='http://www.imdb.com/title/tt1345836/?ref_=fn_tt_tt_1', num_user_for_reviews=2701, language='English', country='USA', content_rating='PG-13', budget=250000000, title_year=2012, actor_2_facebook_likes=23000, imdb_score=8.5, aspect_ratio=2.35, movie_facebook_likes=164000, id='tt1345836'),\n",
       " Row(color=None, director_name='Doug Walker', num_critic_for_reviews=None, duration=None, director_facebook_likes=131, actor_3_facebook_likes=None, actor_2_name='Rob Walker', actor_1_facebook_likes=131, gross=None, genres=['Documentary'], actor_1_name='Doug Walker', movie_title='Star Wars: Episode VII - The Force Awakens\\xa0            ', num_voted_users=8, cast_total_facebook_likes=143, actor_3_name=None, facenumber_in_poster=0, plot_keywords=None, movie_imdb_link='http://www.imdb.com/title/tt5289954/?ref_=fn_tt_tt_1', num_user_for_reviews=None, language=None, country=None, content_rating=None, budget=None, title_year=None, actor_2_facebook_likes=12, imdb_score=7.1, aspect_ratio=None, movie_facebook_likes=0, id='tt5289954')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.csv(DATASET.raw_str('movie_metadata.csv'), header=True, inferSchema=True)\n",
    "        .withColumn('id', F.regexp_extract('movie_imdb_link', 'http:\\/\\/www.imdb.com\\/title\\/([A-z0-9]+)\\/(.*)', 1))\n",
    "        .withColumn('plot_keywords', F.split('plot_keywords', '\\|'))\n",
    "        .withColumn('genres', F.split('genres', '\\|'))\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='Doug Walker', facebook_likes=131, id='Doug Walker'),\n",
       " Row(name='Oliver Platt', facebook_likes=1000, id='Oliver Platt'),\n",
       " Row(name='Snoop Dogg', facebook_likes=881, id='Snoop Dogg'),\n",
       " Row(name='Stephen Root', facebook_likes=939, id='Stephen Root'),\n",
       " Row(name='Laurence Olivier', facebook_likes=1000, id='Laurence Olivier')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_persons = (\n",
    "    df.select(F.col('actor_1_name').alias('name'), F.col('actor_1_facebook_likes').alias('facebook_likes'))\n",
    "        .union(df.select(F.col('actor_2_name').alias('name'), F.col('actor_2_facebook_likes').alias('facebook_likes')))\n",
    "        .union(df.select(F.col('actor_3_name').alias('name'), F.col('actor_3_facebook_likes').alias('facebook_likes')))\n",
    "        .union(df.select(F.col('director_name').alias('name'), F.col('director_facebook_likes').alias('facebook_likes')))\n",
    "        .dropDuplicates(['name'])\n",
    "        .filter(F.col('name').isNotNull())\n",
    "        .withColumn('id', F.col('name'))\n",
    ")\n",
    "print(df_nodes_persons.count())\n",
    "df_nodes_persons.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='Crime', id='Crime'),\n",
       " Row(name='Romance', id='Romance'),\n",
       " Row(name='Thriller', id='Thriller'),\n",
       " Row(name='Adventure', id='Adventure'),\n",
       " Row(name='Drama', id='Drama')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_genres = (\n",
    "    df.select(F.explode('genres').alias('name'))\n",
    "        .dropDuplicates(['name'])\n",
    "        .withColumn('id', F.col('name'))\n",
    "        .filter(F.col('id').isNotNull())\n",
    ")\n",
    "print(df_nodes_genres.count())\n",
    "df_nodes_genres.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='ingratitude', count=2, id='ingratitude'),\n",
       " Row(name='title appears in writing', count=3, id='title appears in writing'),\n",
       " Row(name='space colony', count=2, id='space colony'),\n",
       " Row(name='travel', count=17, id='travel'),\n",
       " Row(name='ransom', count=9, id='ransom')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_keywords = (\n",
    "    df.select(F.explode('plot_keywords').alias('name'))\n",
    "        .groupby('name')\n",
    "        .count().filter('count > 1')\n",
    "        .withColumn('id', F.col('name'))\n",
    "        .filter(F.col('id').isNotNull())\n",
    ")\n",
    "print(df_nodes_keywords.count())\n",
    "df_nodes_keywords.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(color=' Black and White', num_critic_for_reviews=69, duration=123, gross=None, num_voted_users=10718, cast_total_facebook_likes=481, facenumber_in_poster=1, plot_keywords=['huguenot', 'intolerance', 'medicis', 'protestant', 'wedding'], num_user_for_reviews=88, language=None, country='USA', content_rating='Not Rated', budget=385907, title_year=1916, imdb_score=8.0, aspect_ratio=1.33, movie_facebook_likes=691, id='tt0006864', name=\"Intolerance: Love's Struggle Throughout the Ages\\xa0\", timestamp=datetime.datetime(1916, 1, 1, 0, 0)),\n",
       " Row(color=' Black and White', num_critic_for_reviews=1, duration=110, gross=3000000, num_voted_users=5, cast_total_facebook_likes=4, facenumber_in_poster=1, plot_keywords=['family relationships', 'gang', 'idler', 'poorhouse', 'thief'], num_user_for_reviews=1, language=None, country='USA', content_rating=None, budget=100000, title_year=1920, imdb_score=4.8, aspect_ratio=1.33, movie_facebook_likes=0, id='tt0011549', name='Over the Hill to the Poorhouse\\xa0', timestamp=datetime.datetime(1920, 1, 1, 0, 0)),\n",
       " Row(color=' Black and White', num_critic_for_reviews=48, duration=151, gross=None, num_voted_users=4849, cast_total_facebook_likes=108, facenumber_in_poster=0, plot_keywords=['chewing gum', 'climbing a tree', 'france', 'translation problems', 'world war one'], num_user_for_reviews=45, language=None, country='USA', content_rating='Not Rated', budget=245000, title_year=1925, imdb_score=8.3, aspect_ratio=1.33, movie_facebook_likes=226, id='tt0015624', name='The Big Parade\\xa0', timestamp=datetime.datetime(1925, 1, 1, 0, 0)),\n",
       " Row(color=' Black and White', num_critic_for_reviews=260, duration=145, gross=26435, num_voted_users=111841, cast_total_facebook_likes=203, facenumber_in_poster=1, plot_keywords=['art deco', 'bible quote', 'dance', 'silent film', 'worker'], num_user_for_reviews=413, language='German', country='Germany', content_rating='Not Rated', budget=6000000, title_year=1927, imdb_score=8.3, aspect_ratio=1.33, movie_facebook_likes=12000, id='tt0017136', name='Metropolis\\xa0', timestamp=datetime.datetime(1927, 1, 1, 0, 0)),\n",
       " Row(color=' Black and White', num_critic_for_reviews=71, duration=110, gross=9950, num_voted_users=7431, cast_total_facebook_likes=455, facenumber_in_poster=1, plot_keywords=['escape', 'femme fatale', 'german expressionism', 'lust', 'violence'], num_user_for_reviews=84, language='German', country='Germany', content_rating='Not Rated', budget=None, title_year=1929, imdb_score=8.0, aspect_ratio=1.33, movie_facebook_likes=926, id='tt0018737', name=\"Pandora's Box\\xa0\", timestamp=datetime.datetime(1929, 1, 1, 0, 0))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_movies = (\n",
    "    df\n",
    "        .withColumn('name', F.col('movie_title'))\n",
    "        .drop(\n",
    "        'genres', 'movie_title',\n",
    "        'actor_1_name', 'actor_1_facebook_likes',\n",
    "        'actor_2_name', 'actor_2_facebook_likes',\n",
    "        'actor_3_name', 'actor_3_facebook_likes',\n",
    "        'director_name', 'director_facebook_likes',\n",
    "        'movie_imdb_link'\n",
    "    ).withColumn('timestamp', F.to_timestamp(F.col('title_year').cast('string'), 'yyyy'))\n",
    "    .filter(F.col('id').isNotNull())\n",
    "    .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_movies.count())\n",
    "df_nodes_movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src='Nicolas Cage', dst='tt0187078'),\n",
       " Row(src='Channing Tatum', dst='tt1578275'),\n",
       " Row(src='Jada Pinkett Smith', dst='tt0117218'),\n",
       " Row(src='Matt Damon', dst='tt1385826'),\n",
       " Row(src='Kevin Spacey', dst='tt0120623')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_acted_in = (\n",
    "    df.select(F.col('id').alias('movie_id'), F.col('actor_1_name').alias('actor_name'))\n",
    "        .union(df.select(F.col('id').alias('movie_id'), F.col('actor_2_name').alias('actor_name')))\n",
    "        .union(df.select(F.col('id').alias('movie_id'), F.col('actor_3_name').alias('actor_name')))\n",
    "        .dropDuplicates(['movie_id', 'actor_name'])\n",
    "        .select(F.col('actor_name').alias('src'), F.col('movie_id').alias('dst'))\n",
    "        .filter(F.col('src').isNotNull())\n",
    "        .filter(F.col('dst').isNotNull())\n",
    ")\n",
    "df_edges_acted_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src='Judd Apatow', dst='tt1201167'),\n",
       " Row(src='Tony Bill', dst='tt0454824'),\n",
       " Row(src='Rod Lurie', dst='tt0272020'),\n",
       " Row(src='Tim Miller', dst='tt1431045'),\n",
       " Row(src='Anthony Hemingway', dst='tt0485985')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_directed = (\n",
    "    df.select(F.col('id').alias('movie_id'), F.col('director_name').alias('director_name'))\n",
    "        .dropDuplicates(['movie_id', 'director_name'])\n",
    "        .select(F.col('director_name').alias('src'), F.col('movie_id').alias('dst'))\n",
    "        .filter(F.col('src').isNotNull())\n",
    "        .filter(F.col('dst').isNotNull())\n",
    ")\n",
    "df_edges_directed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src='tt1375666', dst='Adventure'),\n",
       " Row(src='tt0413267', dst='Adventure'),\n",
       " Row(src='tt0436339', dst='Animation'),\n",
       " Row(src='tt1680310', dst='Action'),\n",
       " Row(src='tt1320261', dst='Family')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_has_genre = (\n",
    "    df.select(F.col('id').alias('movie_id'), F.explode('genres').alias('genre'))\n",
    "        .dropDuplicates(['movie_id', 'genre'])\n",
    "        .select(F.col('movie_id').alias('src'), F.col('genre').alias('dst'))\n",
    "        .filter(F.col('src').isNotNull())\n",
    "        .filter(F.col('dst').isNotNull())\n",
    ")\n",
    "df_edges_has_genre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src='tt0371746', dst='billionaire'),\n",
       " Row(src='tt0938283', dst='kingdom'),\n",
       " Row(src='tt1229238', dst='race against time'),\n",
       " Row(src='tt0122151', dst='lapd'),\n",
       " Row(src='tt0177971', dst='storm')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_has_keyword = (\n",
    "    df.select(F.col('id').alias('movie_id'), F.explode('plot_keywords').alias('plot_keywords'))\n",
    "        .dropDuplicates(['movie_id', 'plot_keywords'])\n",
    "        .select(F.col('movie_id').alias('src'), F.col('plot_keywords').alias('dst'))\n",
    "        .filter(F.col('src').isNotNull())\n",
    "        .filter(F.col('dst').isNotNull())\n",
    "        .join(df_nodes_keywords.select('id'), F.col('id') ==  F.col('dst'), 'inner')\n",
    "        .drop('id')\n",
    ")\n",
    "df_edges_has_keyword.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_persons.write.parquet(DATASET.processed_str('nodes_Person'), mode='overwrite')\n",
    "df_nodes_genres.write.parquet(DATASET.processed_str('nodes_Genre'), mode='overwrite')\n",
    "df_nodes_keywords.write.parquet(DATASET.processed_str('nodes_Keyword'), mode='overwrite')\n",
    "df_nodes_movies.write.parquet(DATASET.processed_str('nodes_Movie'), mode='overwrite')\n",
    "\n",
    "df_edges_acted_in.write.parquet(DATASET.processed_str('edges_ACTED_IN'), mode='overwrite')\n",
    "df_edges_directed.write.parquet(DATASET.processed_str('edges_DIRECTED'), mode='overwrite')\n",
    "df_edges_has_genre.write.parquet(DATASET.processed_str('edges_HAS_GENRE'), mode='overwrite')\n",
    "df_edges_has_keyword.write.parquet(DATASET.processed_str('edges_HAS_KEYWORD'), mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSchema(_path=PosixPath('/dd_volume/Development/Python/Thesis/code/datasets/data/processed/imdb-5000-movie-dataset'), nodes={'Person': NodeSchema(_type='Person', _schema=..., label='name', properties={'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'facebook_likes': GraphProperty(_name='facebook_likes', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None), 'Genre': NodeSchema(_type='Genre', _schema=..., label='name', properties={'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None), 'Keyword': NodeSchema(_type='Keyword', _schema=..., label='name', properties={'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'count': GraphProperty(_name='count', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None), 'Movie': NodeSchema(_type='Movie', _schema=..., label='name', properties={'color': GraphProperty(_name='color', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'num_critic_for_reviews': GraphProperty(_name='num_critic_for_reviews', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'duration': GraphProperty(_name='duration', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'gross': GraphProperty(_name='gross', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'num_voted_users': GraphProperty(_name='num_voted_users', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'cast_total_facebook_likes': GraphProperty(_name='cast_total_facebook_likes', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'facenumber_in_poster': GraphProperty(_name='facenumber_in_poster', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'plot_keywords': GraphProperty(_name='plot_keywords', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'num_user_for_reviews': GraphProperty(_name='num_user_for_reviews', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'language': GraphProperty(_name='language', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'country': GraphProperty(_name='country', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'content_rating': GraphProperty(_name='content_rating', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'budget': GraphProperty(_name='budget', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'title_year': GraphProperty(_name='title_year', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'imdb_score': GraphProperty(_name='imdb_score', dtype=DType(atomic=<DTypeAtomic.FLOAT: 'float'>, array=False)), 'aspect_ratio': GraphProperty(_name='aspect_ratio', dtype=DType(atomic=<DTypeAtomic.FLOAT: 'float'>, array=False)), 'movie_facebook_likes': GraphProperty(_name='movie_facebook_likes', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'timestamp': GraphProperty(_name='timestamp', dtype=DType(atomic=<DTypeAtomic.DATETIME: 'datetime'>, array=False))}, dynamic=DynamicConfig(timestamp='timestamp', interaction=False))}, edges={'ACTED_IN': EdgeSchema(_type='ACTED_IN', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Person', target_type='Movie', directed=True), 'DIRECTED': EdgeSchema(_type='DIRECTED', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Person', target_type='Movie', directed=True), 'HAS_GENRE': EdgeSchema(_type='HAS_GENRE', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Movie', target_type='Genre', directed=True), 'HAS_KEYWORD': EdgeSchema(_type='HAS_KEYWORD', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Movie', target_type='Keyword', directed=True)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shared.schema.graph import GraphSchema, NodeSchema, EdgeSchema\n",
    "\n",
    "(\n",
    "    GraphSchema()\n",
    "        .add_node_schema('Person', NodeSchema.from_spark(df_nodes_persons.schema, label='name'))\n",
    "        .add_node_schema('Genre', NodeSchema.from_spark(df_nodes_genres.schema, label='name'))\n",
    "        .add_node_schema('Keyword', NodeSchema.from_spark(df_nodes_keywords.schema, label='name'))\n",
    "        .add_node_schema('Movie', NodeSchema.from_spark(df_nodes_movies.schema, label='name', timestamp='timestamp', interaction=False))\n",
    "        .add_edge_schema('ACTED_IN', EdgeSchema.from_spark(df_edges_acted_in.schema, source_type='Person', target_type='Movie', directed=True))\n",
    "        .add_edge_schema('DIRECTED', EdgeSchema.from_spark(df_edges_directed.schema, source_type='Person', target_type='Movie', directed=True))\n",
    "        .add_edge_schema('HAS_GENRE', EdgeSchema.from_spark(df_edges_has_genre.schema, source_type='Movie', target_type='Genre', directed=True))\n",
    "        .add_edge_schema('HAS_KEYWORD', EdgeSchema.from_spark(df_edges_has_keyword.schema, source_type='Movie', target_type='Keyword', directed=True))\n",
    "        .save_schema(DATASET.processed())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
