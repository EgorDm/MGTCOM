{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Whether custom features should be added to the dataset.\n",
    "# For this you need to run datasets/notebooks/development/import-sw-data.ipynb first\n",
    "ADD_FEATURES=False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from shared.schema import DatasetSchema\n",
    "\n",
    "DATASET = DatasetSchema.load_schema('star-wars')\n",
    "DATASET.save_schema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/09 17:56:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(f'{DATASET}')\n",
    "         .config('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "         .config(\"spark.executor.memory\", \"8g\")\n",
    "         .config(\"spark.driver.memory\", \"8g\")\n",
    "         .config(\"spark.memory.offHeap.enabled\", True)\n",
    "         .config(\"spark.memory.offHeap.size\", \"16g\")\n",
    "         .getOrCreate())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_edges = []\n",
    "for file in DATASET.raw().glob('starwars-episode-*ns.json'):\n",
    "    _, _, episode, link_type = file.stem.split('-')\n",
    "    with file.open('r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    nodes = list(data['nodes'])\n",
    "    edges = data['links']\n",
    "    for e in edges:\n",
    "        all_edges.append({\n",
    "            'source': nodes[e['source']]['name'],\n",
    "            'target': nodes[e['target']]['name'],\n",
    "            'time': int(episode),\n",
    "            'weight': e['value'],\n",
    "            'type': link_type\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(source='CAMIE', target='LUKE', time=4, type='interactions', weight=2),\n Row(source='BIGGS', target='CAMIE', time=4, type='interactions', weight=2),\n Row(source='BIGGS', target='LUKE', time=4, type='interactions', weight=4),\n Row(source='DARTH VADER', target='LEIA', time=4, type='interactions', weight=1),\n Row(source='BERU', target='LUKE', time=4, type='interactions', weight=3)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(all_edges)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(name='C-3PO', id=0),\n Row(name='JERJERROD', id=1),\n Row(name='BERU', id=2),\n Row(name='LANDO', id=3),\n Row(name='CAMIE', id=4)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_tmp = (\n",
    "    df\n",
    "        .select(F.col('source').alias('name'))\n",
    "        .union(df.select(F.col('target').alias('name')))\n",
    "        .distinct()\n",
    "        .withColumn('id', F.monotonically_increasing_id())\n",
    ")\n",
    "print(df_nodes_tmp.count())\n",
    "df_nodes_tmp.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(time=2, type='mentions', src=25, dst=24, weight=24),\n Row(time=2, type='mentions', src=25, dst=91, weight=1),\n Row(time=3, type='mentions', src=25, dst=11, weight=2),\n Row(time=3, type='mentions', src=39, dst=22, weight=1),\n Row(time=4, type='mentions', src=8, dst=24, weight=36)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_edges = (\n",
    "    df.join(df_nodes_tmp.alias('s'), df.source == F.col('s.name'), 'left')\n",
    "        .join(df_nodes_tmp.alias('t'), df.target ==  F.col('t.name'), 'left')\n",
    "        .withColumn('src', F.col('s.id'))\n",
    "        .withColumn('dst', F.col('t.id'))\n",
    "        .select('time', 'type', 'src', 'dst', 'weight')\n",
    "        .dropDuplicates(['time', 'src', 'dst', 'type'])\n",
    ")\n",
    "print(df_all_edges.count())\n",
    "df_all_edges.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(time=1, src=24, dst=45, weight=1),\n Row(time=4, src=0, dst=28, weight=2),\n Row(time=1, src=25, dst=77, weight=2),\n Row(time=2, src=36, dst=99, weight=2),\n Row(time=5, src=8, dst=105, weight=1)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_interactions = (\n",
    "    df_all_edges.filter(F.col('type') == 'interactions')\n",
    "        .drop('type')\n",
    ")\n",
    "print(df_edges_interactions.count())\n",
    "df_edges_interactions.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(time=3, src=12, dst=86, weight=1),\n Row(time=7, src=47, dst=53, weight=1),\n Row(time=3, src=84, dst=27, weight=6),\n Row(time=2, src=21, dst=99, weight=2),\n Row(time=4, src=12, dst=8, weight=28)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_mentions = (\n",
    "    df_all_edges.filter(F.col('type') == 'mentions')\n",
    "        .drop('type')\n",
    "        .distinct()\n",
    ")\n",
    "print(df_edges_mentions.count())\n",
    "df_edges_mentions.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    from pymongo import MongoClient\n",
    "    import unicodedata\n",
    "    import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    client = MongoClient(\"mongodb://root:helloworld@127.0.0.1/wiki.starwars?authSource=admin\")\n",
    "    collection = client.wiki.wookiepedia.characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "if ADD_FEATURES:\n",
    "    db_items_df = pd.DataFrame(collection.find({}, {\"title\": 1, 'text': 1})).set_index(\"_id\")\n",
    "    db_items_df['text'] = db_items_df['text'].str.lower().apply(strip_accents)\n",
    "    db_items_df['title'] = db_items_df['title'].str.lower().apply(strip_accents)\n",
    "    db_items_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "VOCAB = {\n",
    "    'HAN': 'Han Solo',\n",
    "    'KYLO REN': 'Ben Solo',\n",
    "    'REY': 'Rey Skywalker',\n",
    "    'EMPEROR': 'Darth Sidious',\n",
    "    'DARTH VADER': 'Anakin Skywalker',\n",
    "    'FODE/BEED': 'Fodesinbeed Annodue',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    import Levenshtein\n",
    "\n",
    "def distance(a, b):\n",
    "    return Levenshtein.jaro_winkler(a.lower(), b.lower())\n",
    "\n",
    "def find_match(title):\n",
    "    title = title.lower().replace('count', '').replace('senator', '')\\\n",
    "        .replace('captain', '').replace('admiral', '').replace('general', '')\\\n",
    "        .replace('darth', '').replace('colonel', '').replace('clone', '')\n",
    "\n",
    "    candidates = db_items_df[db_items_df['title'].apply(lambda x: title in x.lower())]\n",
    "\n",
    "    # if len(candidates) == 0:\n",
    "    #     candidate_idx = db_items_df['text'].apply(lambda x: x.count(title.lower())).argsort().head(10)\n",
    "    #     candidates = db_items_df.iloc[candidate_idx]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        candidates = db_items_df\n",
    "\n",
    "    idx = candidates['title'].apply(lambda x: distance(x, title)).argmax()\n",
    "    match = candidates.iloc[idx]\n",
    "\n",
    "    return match\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    names_df = df_nodes_tmp.toPandas()\n",
    "    node_details = []\n",
    "    for index, row in names_df.iterrows():\n",
    "        name = row['name'] if row['name'] not in VOCAB else VOCAB[row['name']]\n",
    "        match = find_match(name)\n",
    "        node_details.append({\n",
    "            **row.to_dict(),\n",
    "            'match_title': match['title'],\n",
    "            'match_id': str(match.name)\n",
    "        })\n",
    "\n",
    "    node_details_df = pd.DataFrame(node_details)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    node_details_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    from bson.objectid import ObjectId\n",
    "    import numpy as np\n",
    "\n",
    "    node_props = []\n",
    "    for item in node_details:\n",
    "        data = collection.find_one({'_id': ObjectId(item['match_id'])}, {'properties': 1})\n",
    "        node_props.append({\n",
    "            'id': item['id'],\n",
    "            **data['properties']\n",
    "        })\n",
    "\n",
    "    def strip_tokens(x):\n",
    "        if not x or (isinstance(x, float) and np.isnan(x)):\n",
    "            return []\n",
    "        return [str(e).strip() for e in x]\n",
    "\n",
    "    node_details_df = pd.DataFrame(node_props)\n",
    "    node_details_df.drop(columns=['1', '2', 'kajidic', 'clan', 'armament', 'plating', 'sensor', 'width', 'length', 'cost', 'line', 'manufacturer', 'creator', 'model', 'class', 'image'], inplace=True)\n",
    "    node_details_df = node_details_df.replace('', np.nan)\n",
    "    node_details_df['hair'] = node_details_df['hair'].str.split(',|;').apply(strip_tokens)\n",
    "    node_details_df['eyes'] = node_details_df['skin'].str.split(',|;').apply(strip_tokens)\n",
    "    node_details_df['cyber'] = node_details_df['cyber'].str.split(',|;').apply(strip_tokens)\n",
    "    node_details_df['skin'] = node_details_df['skin'].str.split(',|;').apply(strip_tokens)\n",
    "    node_details_df['masters'] = node_details_df['masters'].str.split(r'\\|').apply(strip_tokens)\n",
    "    node_details_df['apprentices'] = node_details_df['apprentices'].str.split(r'\\|').apply(strip_tokens)\n",
    "    node_details_df['affiliation'] = node_details_df['affiliation'].str.split(r'\\|').apply(strip_tokens)\n",
    "    # node_details_df['height'] = node_details_df['height'].apply(lambda x: x.split()[0] if x and isinstance(x, str) else x)\n",
    "    # node_details_df['mass'] = node_details_df['mass'].apply(lambda x: x.split()[0] if x and isinstance(x, str) else x)\n",
    "    node_details_df = node_details_df.astype(object).where(pd.notnull(node_details_df), None)\n",
    "    node_details_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    node_details_df['homeworld'] = node_details_df['homeworld'].fillna('Unknown')\n",
    "    node_details_df['gender'] = node_details_df['gender'].fillna('Unknown')\n",
    "    node_details_df['species'] = node_details_df['species'].fillna('Unknown')\n",
    "    node_details_df['type'] = node_details_df['type'].fillna('Unknown')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    from datasets.feature_transform import MultiRareLabelEncoder, MOneHotEncoder\n",
    "\n",
    "    mrare_encoder = MultiRareLabelEncoder(tol=0.05, n_categories=8)\n",
    "    mfeature_df = mrare_encoder.fit_transform(node_details_df[['affiliation']])\n",
    "\n",
    "    oh_encoder = MOneHotEncoder()\n",
    "    mfeature_df = oh_encoder.fit_transform(mfeature_df[['affiliation']]).add_prefix('feat_')\n",
    "\n",
    "    mfeature_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    from feature_engine.encoding import RareLabelEncoder, OneHotEncoder\n",
    "\n",
    "    rare_encoder = RareLabelEncoder(tol=0.05, n_categories=6)\n",
    "    feature_df = rare_encoder.fit_transform(node_details_df[['homeworld', 'gender', 'species', 'type']])\n",
    "\n",
    "    oh_encoder = OneHotEncoder()\n",
    "    feature_df = oh_encoder.fit_transform(feature_df[['homeworld', 'gender', 'species', 'type']]).add_prefix('feat_')\n",
    "\n",
    "    feature_df['feat_species_Droid'] = node_details_df['is_droid'].apply(lambda x: 1 if x else 0)\n",
    "    feature_df['feat_hasMaster'] = node_details_df['masters'].apply(lambda x: 1 if len(x) else 0)\n",
    "    feature_df['feat_hasApprentices'] = node_details_df['apprentices'].apply(lambda x: 1 if len(x) else 0)\n",
    "    feature_df['feat_hasCyber'] = node_details_df['cyber'].apply(lambda x: 1 if len(x) else 0)\n",
    "\n",
    "    feature_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    node_details_and_features_df = node_details_df.join(feature_df).join(mfeature_df)\n",
    "    node_details_and_features_df.columns = [c.replace(' ', '') for c in node_details_and_features_df.columns]\n",
    "    node_details_and_features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "if ADD_FEATURES:\n",
    "    df_nodes_feat = spark.createDataFrame(node_details_and_features_df)\n",
    "    df_nodes_feat = (\n",
    "        df_nodes_feat\n",
    "            .withColumn('full_name', F.col('name'))\n",
    "            .drop('name')\n",
    "    )\n",
    "    df_nodes_feat.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(name='C-3PO', id=0),\n Row(name='JERJERROD', id=1),\n Row(name='BERU', id=2),\n Row(name='LANDO', id=3),\n Row(name='CAMIE', id=4)]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ADD_FEATURES:\n",
    "    df_nodes = (\n",
    "        df_nodes_tmp\n",
    "            .join(df_nodes_feat, on='id', how='left')\n",
    "    )\n",
    "else:\n",
    "    df_nodes = df_nodes_tmp\n",
    "df_nodes.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes.write.parquet(DATASET.processed_str('nodes_Character'), mode='overwrite')\n",
    "\n",
    "df_edges_interactions.write.parquet(DATASET.processed_str('edges_INTERACTIONS'), mode='overwrite')\n",
    "df_edges_mentions.write.parquet(DATASET.processed_str('edges_MENTIONS'), mode='overwrite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphSchema(_path=PosixPath('/data/pella/projects/University/Thesis/Thesis/code/storage/datasets/processed/star-wars'), nodes={'Character': NodeSchema(_type='Character', _schema=..., label='name', properties={'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'homeworld': GraphProperty(_name='homeworld', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'birth': GraphProperty(_name='birth', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'death': GraphProperty(_name='death', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'height': GraphProperty(_name='height', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'mass': GraphProperty(_name='mass', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'gender': GraphProperty(_name='gender', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'equipment': GraphProperty(_name='equipment', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'affiliation': GraphProperty(_name='affiliation', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'is_droid': GraphProperty(_name='is_droid', dtype=DType(atomic=<DTypeAtomic.BOOL: 'boolean'>, array=False)), 'type': GraphProperty(_name='type', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'species': GraphProperty(_name='species', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'hair': GraphProperty(_name='hair', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'eyes': GraphProperty(_name='eyes', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'skin': GraphProperty(_name='skin', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'cyber': GraphProperty(_name='cyber', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'masters': GraphProperty(_name='masters', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'apprentices': GraphProperty(_name='apprentices', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'feat_homeworld_Tatooine': GraphProperty(_name='feat_homeworld_Tatooine', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_homeworld_Rare': GraphProperty(_name='feat_homeworld_Rare', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_homeworld_Naboo': GraphProperty(_name='feat_homeworld_Naboo', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_homeworld_Alderaan': GraphProperty(_name='feat_homeworld_Alderaan', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_homeworld_Unknown': GraphProperty(_name='feat_homeworld_Unknown', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_gender_Masculineprogramming': GraphProperty(_name='feat_gender_Masculineprogramming', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_gender_Male': GraphProperty(_name='feat_gender_Male', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_gender_Female': GraphProperty(_name='feat_gender_Female', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_gender_Unknown': GraphProperty(_name='feat_gender_Unknown', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_gender_Feminineprogramming': GraphProperty(_name='feat_gender_Feminineprogramming', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_species_Unknown': GraphProperty(_name='feat_species_Unknown', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_species_Human': GraphProperty(_name='feat_species_Human', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_species_Rare': GraphProperty(_name='feat_species_Rare', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Unknown': GraphProperty(_name='feat_type_Unknown', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_FirstOrder': GraphProperty(_name='feat_type_FirstOrder', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Resistance': GraphProperty(_name='feat_type_Resistance', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Rare': GraphProperty(_name='feat_type_Rare', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Jedi': GraphProperty(_name='feat_type_Jedi', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Criminal': GraphProperty(_name='feat_type_Criminal', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_GalacticEmpire': GraphProperty(_name='feat_type_GalacticEmpire', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_GalacticRepublic': GraphProperty(_name='feat_type_GalacticRepublic', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_type_Rebel': GraphProperty(_name='feat_type_Rebel', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_species_Droid': GraphProperty(_name='feat_species_Droid', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_hasMaster': GraphProperty(_name='feat_hasMaster', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_hasApprentices': GraphProperty(_name='feat_hasApprentices', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_hasCyber': GraphProperty(_name='feat_hasCyber', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_GalacticEmpire': GraphProperty(_name='feat_affiliation_GalacticEmpire', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_AlliancetoRestoretheRepublic': GraphProperty(_name='feat_affiliation_AlliancetoRestoretheRepublic', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_Resistance': GraphProperty(_name='feat_affiliation_Resistance', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_NewRepublic': GraphProperty(_name='feat_affiliation_NewRepublic', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_JediOrder': GraphProperty(_name='feat_affiliation_JediOrder', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'feat_affiliation_GalacticRepublic': GraphProperty(_name='feat_affiliation_GalacticRepublic', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'full_name': GraphProperty(_name='full_name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None)}, edges={'INTERACTIONS': EdgeSchema(_type='INTERACTIONS', _schema=..., label=None, properties={'time': GraphProperty(_name='time', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'weight': GraphProperty(_name='weight', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False))}, dynamic=DynamicConfig(timestamp='time', interaction=True), source_type='Character', target_type='Character', directed=False), 'MENTIONS': EdgeSchema(_type='MENTIONS', _schema=..., label=None, properties={'time': GraphProperty(_name='time', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'weight': GraphProperty(_name='weight', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False))}, dynamic=DynamicConfig(timestamp='time', interaction=True), source_type='Character', target_type='Character', directed=True)})"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shared.schema.graph import GraphSchema, NodeSchema, EdgeSchema\n",
    "\n",
    "(\n",
    "    GraphSchema()\n",
    "        .add_node_schema('Character', NodeSchema.from_spark(df_nodes.schema, label='name'))\n",
    "        .add_edge_schema('INTERACTIONS', EdgeSchema.from_spark(df_edges_interactions.schema, source_type='Character', target_type='Character', directed=False, timestamp='time', interaction=True))\n",
    "        .add_edge_schema('MENTIONS', EdgeSchema.from_spark(df_edges_mentions.schema, source_type='Character', target_type='Character', directed=True, timestamp='time', interaction=True))\n",
    "        .save_schema(DATASET.processed())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}