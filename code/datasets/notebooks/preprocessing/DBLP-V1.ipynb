{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Exception in thread \"main\" java.nio.file.NoSuchFileException: /tmp/tmpx511epyb/connection5286146727792970879.info\n",
      "\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n",
      "\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n",
      "\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n",
      "\tat sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n",
      "\tat java.nio.file.Files.newByteChannel(Files.java:361)\n",
      "\tat java.nio.file.Files.createFile(Files.java:632)\n",
      "\tat java.nio.file.TempFileHelper.create(TempFileHelper.java:138)\n",
      "\tat java.nio.file.TempFileHelper.createTempFile(TempFileHelper.java:161)\n",
      "\tat java.nio.file.Files.createTempFile(Files.java:852)\n",
      "\tat org.apache.spark.api.python.PythonGatewayServer$.main(PythonGatewayServer.scala:52)\n",
      "\tat org.apache.spark.api.python.PythonGatewayServer.main(PythonGatewayServer.scala)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:955)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from shared.schema import DatasetSchema\n",
    "\n",
    "DATASET = DatasetSchema.load_schema('DBLP-V1')\n",
    "DATASET.save_schema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/23 01:42:56 WARN Utils: Your hostname, megatron resolves to a loopback address: 127.0.1.1; using 192.168.1.89 instead (on interface enp7s0)\n",
      "22/01/23 01:42:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/23 01:42:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/23 01:42:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/01/23 01:42:58 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(f'{DATASET}')\n",
    "         .config('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
    "         .config(\"spark.executor.memory\", \"8g\")\n",
    "         .config(\"spark.driver.memory\", \"8g\")\n",
    "         .config(\"spark.memory.offHeap.enabled\", True)\n",
    "         .config(\"spark.memory.offHeap.size\", \"16g\")\n",
    "         .getOrCreate())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(value=['629814', '#*Automated Deduction in Geometry: 5th International Workshop, ADG 2004, Gainesville, FL, USA, September 16-18, 2004, Revised Papers (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)', '#@Hoon Hong,Dongming Wang', '#t2006', '#c', '#index0']),\n Row(value=['#*A+ Certification Core Hardware (Text & Lab Manual)', '#@Charles J. Brooks', '#t2003', '#c', '#index1']),\n Row(value=['#*Performance engineering in industry: current practices and adoption challenges', '#@Ahmed E. Hassan,Parminder Flora', '#t2007', '#cProceedings of the 6th international workshop on Software and performance', '#index2', '#!This panel session discusses performance engineering practices in industry. Presentations in the session will explore the use of lightweight techniques and approaches in order to permit the cost effective and rapid adoption of performance modeling research by large industrial software systems.']),\n Row(value=['#*Dude, You Can Do It! How to Build a Sweeet PC', '#@Darrel Creacy,Carlito Vicencio', '#t2005', '#c', '#index3', \"#!Whether you're frustrated with current PC offerings (and their inflated prices) or are simply looking for a cool project to take on, building a computer from the ground up using off-the-shelf parts can offer significant advantages. In these pages, computer dudes Darrel Wayne Creacy and Carlito Vicencio outline those advantages and then show you how to build the computer of your dreams. The pair begins by explaining what components make up a PC and what you need to think about when selecting those components, before helping you determine your needs and suggesting various configurations to fit those uses. Breaking the process down into its simplest terms, the authors provide component lists for a number of different PC setups: for students, home users, multimedia/home-theater enthusiasts, high-end graphic/video/audio producers, and more. Using plain language and plenty of visual and instructional aids--photos, illustrations, diagrams, step-by-step directions, and more--the authors ensure that even someone (like you!) who knows nothing about technology can build the perfect PC! On a more personal note, the authors are donating a percentage of their income from this book to the Breast Cancer Research Foundationï¾\\x96to thank all the women in their lives who have supported them and battled the disease. For more information about BCRF, please visit http://www.bcrfcure.org/.\"]),\n Row(value=['#*What Every Programmer Needs to Know about Security (Advances in Information Security)', '#@Neil Daswani,Anita Kesavan', '#t2006', '#c', '#index4']),\n Row(value=['#*Interpreting Kullback-Leibler divergence with the Neyman-Pearson lemma', '#@Shinto Eguchi,John Copas', '#t2006', '#cJournal of Multivariate Analysis', '#index5', '#%436405', '#!Kullback-Leibler divergence and the Neyman-Pearson lemma are two fundamental concepts in statistics. Both are about likelihood ratios: Kullback-Leibler divergence is the expected log-likelihood ratio, and the Neyman-Pearson lemma is about error rates of likelihood ratio tests. Exploring this connection gives another statistical interpretation of the Kullback-Leibler divergence in terms of the loss of power of the likelihood ratio test when the wrong distribution is used for one of the hypotheses. In this interpretation, the standard non-negativity property of the Kullback-Leibler divergence is essentially a restatement of the optimal property of likelihood ratios established by the Neyman-Pearson lemma. The asymmetry of Kullback-Leibler divergence is overviewed in information geometry.']),\n Row(value=['#*Digital Media: Transformations in Human Communication', '#@Lee Humphreys,Paul Messaris', '#t2006', '#c', '#index6']),\n Row(value=['#*TOPP---the OpenMS proteomics pipeline', '#@Oliver Kohlbacher,Knut Reinert,Clemens Gröpl,Eva Lange,Nico Pfeifer,Ole Schulz-Trieglaff,Marc Sturm', '#t2007', '#cBioinformatics', '#index7', \"#!Motivation: Experimental techniques in proteomics have seen rapid development over the last few years. Volume and complexity of the data have both been growing at a similar rate. Accordingly, data management and analysis are one of the major challenges in proteomics. Flexible algorithms are required to handle changing experimental setups and to assist in developing and validating new methods. In order to facilitate these studies, it would be desirable to have a flexible 'toolbox' of versatile and user-friendly applications allowing for rapid construction of computational workflows in proteomics. Results: We describe a set of tools for proteomics data analysis---TOPP, The OpenMS Proteomics Pipeline. TOPP provides a set of computational tools which can be easily combined into analysis pipelines even by non-experts and can be used in proteomics workflows. These applications range from useful utilities (file format conversion, peak picking) over wrapper applications for known applications (e.g. Mascot) to completely new algorithmic techniques for data reduction and data analysis. We anticipate that TOPP will greatly facilitate rapid prototyping of proteomics data evaluation pipelines. As such, we describe the basic concepts and the current abilities of TOPP and illustrate these concepts in the context of two example applications: the identification of peptides from a raw dataset through database search and the complex analysis of a standard addition experiment for the absolute quantitation of biomarkers. The latter example demonstrates TOPP's ability to construct flexible analysis pipelines in support of complex experimental setups. Availability: The TOPP components are available as open-source software under the lesser GNU public license (LGPL). Source code is available from the project website at www.OpenMS.de Contact: oliver.kohlbacher@uni-tuebingen.de\"]),\n Row(value=['#*Type Graphics and MacIntosh', '#@John Blaint', '#t1987', '#c', '#index8']),\n Row(value=['#*Adaptive Hypermedia and Adaptive Web-Based Systems: 4th International Conference, AH 2006, Dublin, Ireland, June 21-23, 2006, Proceedings (Lecture Notes in Computer Science)', '#@Vincent Wade,Helen Ashman,Barry Smyth', '#t2006', '#c', '#index9'])]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.text(DATASET.raw_str('outputacm.txt'), wholetext=False, lineSep='\\n\\n')\n",
    "        .withColumn('value', F.split(F.col('value'), '\\n'))\n",
    ")\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(title='Automated Deduction in Geometry: 5th International Workshop, ADG 2004, Gainesville, FL, USA, September 16-18, 2004, Revised Papers (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)', authors=['Hoon Hong', 'Dongming Wang'], year=2006, venue='', index='0', references=[], abstract=None),\n Row(title='A+ Certification Core Hardware (Text & Lab Manual)', authors=['Charles J. Brooks'], year=2003, venue='', index='1', references=[], abstract=None),\n Row(title='Performance engineering in industry: current practices and adoption challenges', authors=['Ahmed E. Hassan', 'Parminder Flora'], year=2007, venue='Proceedings of the 6th international workshop on Software and performance', index='2', references=[], abstract='This panel session discusses performance engineering practices in industry. Presentations in the session will explore the use of lightweight techniques and approaches in order to permit the cost effective and rapid adoption of performance modeling research by large industrial software systems.'),\n Row(title='Dude, You Can Do It! How to Build a Sweeet PC', authors=['Darrel Creacy', 'Carlito Vicencio'], year=2005, venue='', index='3', references=[], abstract=\"Whether you're frustrated with current PC offerings (and their inflated prices) or are simply looking for a cool project to take on, building a computer from the ground up using off-the-shelf parts can offer significant advantages. In these pages, computer dudes Darrel Wayne Creacy and Carlito Vicencio outline those advantages and then show you how to build the computer of your dreams. The pair begins by explaining what components make up a PC and what you need to think about when selecting those components, before helping you determine your needs and suggesting various configurations to fit those uses. Breaking the process down into its simplest terms, the authors provide component lists for a number of different PC setups: for students, home users, multimedia/home-theater enthusiasts, high-end graphic/video/audio producers, and more. Using plain language and plenty of visual and instructional aids--photos, illustrations, diagrams, step-by-step directions, and more--the authors ensure that even someone (like you!) who knows nothing about technology can build the perfect PC! On a more personal note, the authors are donating a percentage of their income from this book to the Breast Cancer Research Foundationï¾\\x96to thank all the women in their lives who have supported them and battled the disease. For more information about BCRF, please visit http://www.bcrfcure.org/.\"),\n Row(title='What Every Programmer Needs to Know about Security (Advances in Information Security)', authors=['Neil Daswani', 'Anita Kesavan'], year=2006, venue='', index='4', references=[], abstract=None)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('title', T.StringType(), True),\n",
    "    T.StructField('authors', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('year', T.IntegerType(), True),\n",
    "    T.StructField('venue', T.StringType(), True),\n",
    "    T.StructField('index', T.StringType(), True),\n",
    "    T.StructField('references', T.ArrayType(T.StringType(), False), False),\n",
    "    T.StructField('abstract', T.StringType(), True),\n",
    "])\n",
    "\n",
    "@F.udf(returnType=schema)\n",
    "def parse_citation(lines):\n",
    "    result = {\n",
    "        'title': None,\n",
    "        'authors': [],\n",
    "        'year': None,\n",
    "        'venue': None,\n",
    "        'index': None,\n",
    "        'references': [],\n",
    "        'abstract': None,\n",
    "    }\n",
    "    for line in lines:\n",
    "        if line.startswith('#*'):\n",
    "            result['title'] = line[2:].strip()\n",
    "        elif line.startswith('#@'):\n",
    "            result['authors'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#t'):\n",
    "            result['year'] = int(line[2:].strip())\n",
    "        elif line.startswith('#c'):\n",
    "            result['venue'] = line[2:].strip()\n",
    "        elif line.startswith('#index'):\n",
    "            result['index'] = int(line[6:].strip())\n",
    "        elif line.startswith('#%'):\n",
    "            result['references'].extend(line[2:].strip().split(','))\n",
    "        elif line.startswith('#!'):\n",
    "            result['abstract'] = line[2:].strip()\n",
    "    return result\n",
    "\n",
    "df_papers = df.select(\n",
    "    parse_citation(F.col('value')).alias('parsed_citation')\n",
    ").select('parsed_citation.*').cache()\n",
    "df_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(name=' B. West', id=' B. West'),\n Row(name=' Consumer Electronics Society Staff', id=' Consumer Electronics Society Staff'),\n Row(name=' D. Crookes', id=' D. Crookes'),\n Row(name=' H', id=' H'),\n Row(name=' H. Hsu', id=' H. Hsu')]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_authors = (\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('name'),\n",
    "    ).withColumn('id', F.col('name'))\n",
    "     .filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_authors.count())\n",
    "df_nodes_authors.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12609\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id='(1987)', name='(1987)'),\n Row(id='(1992&ndash;1993)', name='(1992&ndash;1993)'),\n Row(id='(1993&ndash;1994)', name='(1993&ndash;1994)'),\n Row(id='(1994 Supplement)', name='(1994 Supplement)'),\n Row(id='(Fall 1991)', name='(Fall 1991)')]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_venues = (\n",
    "    df_papers.select(\n",
    "        F.col('venue').alias('id'),\n",
    "        F.col('venue').alias('name'),\n",
    "    ).filter(\"id != ''\")\n",
    "     .filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_venues.count())\n",
    "df_nodes_venues.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|  -1|    9|\n",
      "|1900|    1|\n",
      "|1941|    1|\n",
      "|1947|    1|\n",
      "|1949|    1|\n",
      "|1950|    2|\n",
      "|1951|   21|\n",
      "|1952|   35|\n",
      "|1953|   63|\n",
      "|1954|    6|\n",
      "|1955|   14|\n",
      "|1956|   53|\n",
      "|1957|    9|\n",
      "|1958|   45|\n",
      "|1959|   89|\n",
      "|1960|  174|\n",
      "|1961|  343|\n",
      "|1962|  412|\n",
      "|1963|  310|\n",
      "|1964|  359|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_papers.groupby('year').count().orderBy('year').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id='100010', title='MPICH-V2: a Fault Tolerant MPI for Volatile Nodes based on Pessimistic Sender Based Message Logging', authors=['Aurélien Bouteiller', 'Franck Cappello', 'Thomas Herault', 'Géraud Krawezik', 'Pierre Lemarinier', 'Frédéric Magniette'], venue='Proceedings of the 2003 ACM/IEEE conference on Supercomputing', year=2003, abstract='Execution of MPI applications on clusters and Grid deployments suffering from node and network failures motivates the use of fault tolerant MPI implementations. We present MPICH-V2 (the second protocol of MPICH-V project), an automatic fault tolerant MPI implementation using an innovative protocol that removes the most limiting factor of the pessimistic message logging approach: reliable logging of in transit messages. MPICH-V2 relies on uncoordinated checkpointing, sender based message logging and remote reliable logging of message logical clocks. This paper presents the architecture of MPICH-V2, its theoretical foundation and the performance of the implementation. We compare MPICH-V2 to MPICH-V1 and MPICH-P4 evaluating a) its point-to-point performance, b) the performance for the NAS benchmarks, c) the application performance when many faults occur during the execution. Experimental results demonstrate that MPICH-V2 provides performance close to MPICH-P4 for applications using large messages while reducing dramatically the number of reliable nodes compared to MPICH-V1.', timestamp=datetime.datetime(2003, 1, 1, 0, 0)),\n Row(id='100014', title='Message Passing for Parallel Processing of Pressure-Sensitive Paint Images', authors=['Wim Ruyten', 'William E. Sisson'], venue='Proceedings of the 2004 Users Group Conference', year=2004, abstract=\"A message-passing scheme is described that allows parallel processing of pressure-sensitive paint images on a machine with multiple processors or a cluster with multiple nodes. The scheme implements the use of forks and pipes in the former case and socket-based TCP/IP communications in the latter. The approach demonstrates how multiple copies of a nonparallel legacy code (in this case, NASA's Green Boot software) can be made to run in parallel ineither a parent-child or a client-server configuration. Results are presented for benchmark data from wind tunnel tests of an F-16C fighter jet model and NASA's X-38 Crew Return Vehicle.\", timestamp=datetime.datetime(2004, 1, 1, 0, 0)),\n Row(id='100070', title='Personal technologies', authors=[''], venue='Proceedings of the SIGCHI conference on Human factors in computing systems', year=2005, abstract=None, timestamp=datetime.datetime(2005, 1, 1, 0, 0)),\n Row(id='100090', title='Languages of the future', authors=['Tim Sheard'], venue='ACM SIGPLAN Notices', year=2004, abstract='This paper explores a new point in the design space of formal reasoning systems - part programming language, part logical framework. The system is built on a programming language where the user expresses equality constraints between types and the type checker then enforces these constraints. This simple extension to the type system allows the programmer to describe properties of his program in the types of witness objects which can be thought of as concrete evidence that the program has the property desired. These techniques and two other rich typing mechanisms, rank-N polymorphism and extensible kinds, create a powerful new programming idiom for writing programs whose types enforce semantic properties.A language with these features is both a practical programming language and a logic. This marriage between two previously separate entities increases the probability that users will apply formal methods to their programming designs. This kind of synthesis creates the foundations for the languages of the future.', timestamp=datetime.datetime(2004, 1, 1, 0, 0)),\n Row(id='100129', title='Handbook of Corporate Finance: A Business Companion to Financial Markets, Decisions and Techniques', authors=['Glen Arnold'], venue='', year=2005, abstract=None, timestamp=datetime.datetime(2005, 1, 1, 0, 0))]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers = (\n",
    "    df_papers.filter('year > 1900').select(\n",
    "        F.col('index').alias('id'),\n",
    "        'title',\n",
    "        'authors',\n",
    "        'venue',\n",
    "        'year',\n",
    "        'abstract',\n",
    "        F.to_timestamp(F.col('year').cast('string'), 'yyyy').alias('timestamp')\n",
    "    ) .filter(F.col('id').isNotNull())\n",
    "        .dropDuplicates(['id'])\n",
    ")\n",
    "print(df_nodes_papers.count())\n",
    "df_nodes_papers.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_node_ids = (\n",
    "    df_nodes_authors.select('id')\n",
    "        .union(df_nodes_venues.select('id'))\n",
    "        .union(df_nodes_papers.select('id'))\n",
    "        .distinct()\n",
    ")\n",
    "\n",
    "def filter_node_ids(df):\n",
    "    return df.join(\n",
    "        df_node_ids,\n",
    "        F.col('src') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop(\n",
    "        'id'\n",
    "    ).join(\n",
    "        df_node_ids,\n",
    "        F.col('dst') == F.col('id'),\n",
    "        'inner'\n",
    "    ).drop('id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1337700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src='Frédéric Magniette', dst='100010'),\n Row(src='Pierre Lemarinier', dst='100010'),\n Row(src='Thomas Herault', dst='100010'),\n Row(src='Géraud Krawezik', dst='100010'),\n Row(src='Aurélien Bouteiller', dst='100010')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_authored = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.explode(F.col('authors')).alias('src'),\n",
    "        F.col('index').alias('dst'),\n",
    "    ).distinct()\n",
    ")\n",
    "print(df_edges_authored.count())\n",
    "df_edges_authored.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src='164367', dst='(March 1987)'),\n Row(src='515847', dst='(May 1991)'),\n Row(src='528823', dst='(May 1991)'),\n Row(src='517467', dst='(May 1991)'),\n Row(src='600054', dst='3C ON-LINE')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_published_in = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.col('venue').alias('dst'),\n",
    "    ).filter(\"dst != ''\").distinct()\n",
    ")\n",
    "print(df_edges_published_in.count())\n",
    "df_edges_published_in.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(src='581674', dst='100010'),\n Row(src='410794', dst='100010'),\n Row(src='109295', dst='100010'),\n Row(src='50186', dst='100010'),\n Row(src='415704', dst='100090')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_cited = filter_node_ids(\n",
    "    df_papers.select(\n",
    "        F.col('index').alias('src'),\n",
    "        F.explode(F.col('references')).alias('dst'),\n",
    "    )\n",
    "        .withColumn('dst', F.col('dst').cast('long').cast('string'))\n",
    "        .distinct()\n",
    "\n",
    ")\n",
    "print(df_edges_cited.count())\n",
    "df_edges_cited.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_authors.write.parquet(DATASET.processed_str('nodes_Author'), mode='overwrite')\n",
    "df_nodes_venues.write.parquet(DATASET.processed_str('nodes_Venue'), mode='overwrite')\n",
    "df_nodes_papers.write.parquet(DATASET.processed_str('nodes_Paper'), mode='overwrite')\n",
    "\n",
    "df_edges_authored.write.parquet(DATASET.processed_str('edges_AUTHORED'), mode='overwrite')\n",
    "df_edges_published_in.write.parquet(DATASET.processed_str('edges_PUBLISHED_IN'), mode='overwrite')\n",
    "df_edges_cited.write.parquet(DATASET.processed_str('edges_CITED'), mode='overwrite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphSchema(_path=PosixPath('/dd_volume/Development/Python/Thesis/code/datasets/data/processed/DBLP-V1'), nodes={'Author': NodeSchema(_type='Author', _schema=..., label='name', properties={'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None), 'Venue': NodeSchema(_type='Venue', _schema=..., label='name', properties={'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'name': GraphProperty(_name='name', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None), 'Paper': NodeSchema(_type='Paper', _schema=..., label='title', properties={'id': GraphProperty(_name='id', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'title': GraphProperty(_name='title', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'authors': GraphProperty(_name='authors', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=True)), 'venue': GraphProperty(_name='venue', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'year': GraphProperty(_name='year', dtype=DType(atomic=<DTypeAtomic.INT: 'int'>, array=False)), 'abstract': GraphProperty(_name='abstract', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'timestamp': GraphProperty(_name='timestamp', dtype=DType(atomic=<DTypeAtomic.DATETIME: 'datetime'>, array=False))}, dynamic=DynamicConfig(timestamp='timestamp', interaction=False))}, edges={'AUTHORED': EdgeSchema(_type='AUTHORED', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Author', target_type='Paper', directed=True), 'PUBLISHED_IN': EdgeSchema(_type='PUBLISHED_IN', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Paper', target_type='Venue', directed=True), 'CITED': EdgeSchema(_type='CITED', _schema=..., label=None, properties={'src': GraphProperty(_name='src', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False)), 'dst': GraphProperty(_name='dst', dtype=DType(atomic=<DTypeAtomic.STRING: 'string'>, array=False))}, dynamic=None, source_type='Paper', target_type='Paper', directed=True)})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shared.schema.graph import GraphSchema, NodeSchema, EdgeSchema\n",
    "\n",
    "(\n",
    "    GraphSchema()\n",
    "        .add_node_schema('Author', NodeSchema.from_spark(df_nodes_authors.schema, label='name'))\n",
    "        .add_node_schema('Venue', NodeSchema.from_spark(df_nodes_venues.schema, label='name'))\n",
    "        .add_node_schema('Paper', NodeSchema.from_spark(df_nodes_papers.schema, label='title', timestamp='timestamp', interaction=False))\n",
    "        .add_edge_schema('AUTHORED', EdgeSchema.from_spark(df_edges_authored.schema, source_type='Author', target_type='Paper', directed=True))\n",
    "        .add_edge_schema('PUBLISHED_IN', EdgeSchema.from_spark(df_edges_published_in.schema, source_type='Paper', target_type='Venue', directed=True))\n",
    "        .add_edge_schema('CITED', EdgeSchema.from_spark(df_edges_cited.schema, source_type='Paper', target_type='Paper', directed=True))\n",
    "        .save_schema(DATASET.processed())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ground truth communities\n",
    "Using same methodology as in:\n",
    "\n",
    "J. Yang and J. Leskovec, “Defining and evaluating network communities based on ground-truth,” in Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics, New York, NY, USA, Aug. 2012, pp. 1–8. doi: 10.1145/2350190.2350193."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(venue='Proceedings of the 2009 ICSE Workshop on Comparison and Versioning of Software Models', count=12), Row(venue='Empirical Software Engineering', count=45), Row(venue='Computers in the Schools', count=351), Row(venue='The IFIP TC2/WG 2.1 Working Conference on Program specification and transformation', count=24), Row(venue='Library Hi Tech', count=315), Row(venue=\"International Workshop All '86 on Analogical and inductive inference\", count=16), Row(venue='Proceedings of the Third International Conference on Medical Image Computing and Computer-Assisted Intervention', count=133), Row(venue='Proceedings of the IFIP TC8/WG8.1 Working Conference on Information Systems in the WWW Environment', count=21), Row(venue='Workshop on Evolutionary Models and Strategies, Workshop on Parallel Processing: Logic, Organization, and Technology: Parallelism, Learning, Evolution', count=27), Row(venue='Proceedings of the 14th Annual International Cryptology Conference on Advances in Cryptology', count=37), Row(venue='Proceedings of the 6th International Workshop on Logic Programming Synthesis and Transformation', count=18), Row(venue='Proceedings of the Proceedings of the 2006 IEEE International Conference on Network Protocols', count=35), Row(venue=\"Proceedings of the IEEE Visualization '93 Workshop on Database Issues for Data Visualization\", count=16), Row(venue='Proceedings of the 4th Asian Computing Science Conference on Advances in Computing Science', count=22), Row(venue='Proceedings of the 29th International Conference on Software Engineering Workshops', count=127), Row(venue='Proceedings of the 2002 conference on APL: array processing languages: lore, problems, and applications', count=8), Row(venue='Trends in computer algebra', count=11), Row(venue='Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization', count=18), Row(venue='Knowledge Management for Health Care Procedures: ECAI 2008 Workshop, K4HelP 2008, Patras, Greece, July 21, 2008, Revised Selected Papers', count=15), Row(venue=\"Proceedings of the conference on TRI-Ada '91: today's accomplishments; tomorrow's expectations\", count=54), Row(venue='User Services Conference', count=22), Row(venue='Proceedings of the sixth international conference on APL', count=67), Row(venue='Integrated Circuit and System Design. Power and Timing Modeling, Optimization and Simulation: 18th International Workshop, PATMOS 2008, Lisbon, Portugal, September 10-12, 2008. Revised Selected Papers', count=59), Row(venue='Proceedings of the 14th Annual Symposium on Theoretical Aspects of Computer Science', count=2), Row(venue='Proceedings of the Third European Conference-Volume II on Computer Vision - Volume II', count=2), Row(venue='Proceedings of the First IEEE International Workshop on Biologically Motivated Computer Vision', count=64), Row(venue='Adaptive user support: ergonomic design of manually and automatically adaptable software', count=5), Row(venue='Virtual Reality', count=45), Row(venue='Proceedings of the Asia-Pacific symposium on Information visualisation - Volume 24', count=15), Row(venue='ACM Transactions on Algorithms (TALG)', count=50), Row(venue=\"Proceedings of the conference on TRI-Ada '93\", count=33), Row(venue='Proceedings of the 6th International Symposium on Graph Drawing', count=21), Row(venue='Eiffel, Gemeinsame Fachtagung des German Chapter of the ACM mit der Gesellschaft f&uuml;r Informatik (GI)', count=9), Row(venue='The first computers: history and architectures', count=24), Row(venue='Proceedings of the twentieth annual ACM symposium on Principles of distributed computing', count=38), Row(venue='Proceedings of the 32nd IEEE Conference on Local Computer Networks', count=159), Row(venue='Proceedings of the 2007 SIGCOMM workshop on Internet network management', count=18), Row(venue='Proceedings of the 2009 IEEE international conference on Symposium on Information Theory - Volume 1', count=41), Row(venue='Proceedings of the 13th European Conference on Machine Learning', count=45), Row(venue='Proceedings of the 1st Integer Programming and Combinatorial Optimization Conference', count=37), Row(venue='Proceedings of the Communication Networks and Services Research Conference', count=90), Row(venue='Proceedings of the 2008 Panhellenic Conference on Informatics', count=45), Row(venue='Proceedings of the 10th WSEAS International Conference on Mathematical Methods and Computational Techniques in Electrical Engineering', count=52), Row(venue='Medical Imaging and Informatics: 2nd International Conference, MIMI 2007, Beijing, China, August 14-16, 2007 Revised Selected Papers', count=51), Row(venue='Proceedings of the 2nd international conference on Verified Software: Theories, Tools, Experiments', count=26), Row(venue='Lecture Notes In Computer Science; Vol. 5274', count=1), Row(venue='Proceedings of the 5th international symposium on Parallel and Distributed Processing and Applications', count=13), Row(venue='Proceedings of the 1988 ACM conference on Computer-supported cooperative work', count=31), Row(venue='Proceedings of the Twenty-First Annual Hawaii International Conference on Architecture Track', count=32), Row(venue='Proceedings of the 2009 International Workshop on Social Informatics', count=14), Row(venue='Proceedings of the 2009 Ninth Annual International Symposium on Applications and the Internet', count=77), Row(venue='Proceedings of the 25th International Conference on Logic Programming', count=73), Row(venue='Proceedings of the Third Workshop on Scalable Natural Language Understanding', count=14), Row(venue='Proceedings of the ACM SIGPLAN SIGOA symposium on Text manipulation', count=8), Row(venue='Digital Image Processing Systems', count=7), Row(venue='Computer Security and Industrial Cryptography - State of the Art and Evolution, ESAT Course', count=2), Row(venue='Proceedings of the 21st Annual Computer Security Applications Conference', count=58), Row(venue='Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems - Volume 2', count=220), Row(venue='Proceedings of the 2nd conference on European computing conference', count=79), Row(venue='Proceeding of the 2nd international workshop on Patent information retrieval', count=15), Row(venue='Proceedings of the 1994 International Zurich Seminar on Digital Communications: Mobile Communications: Advanced Systems and Components', count=37), Row(venue='Proceedings of the Third International Conference on Unconventional Models of Computation', count=26), Row(venue='Proceedings of the 20th Conference on Foundations of Software Technology and Theoretical Computer Science', count=42), Row(venue='Proceedings of the 19th Annual International Cryptology Conference on Advances in Cryptology', count=39), Row(venue='Proceedings of the IFIP WG3.4 Working Conference on Computer Mediated Education of Information Technology Professionals and Advanced End-Users', count=37), Row(venue='Proceedings of the 2007 ACM workshop on Digital identity management', count=14), Row(venue='Proceedings of the Sixth International Workshop on Database Machines', count=24), Row(venue='Proceedings of the 10th International Conference on Artificial Intelligence: Methodology, Systems, and Applications', count=28), Row(venue='Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval', count=240), Row(venue='Proceedings of the Second International Workshop on Advances in Databases and Information Systems', count=29), Row(venue='Proceedings of the 4th International Conference on Practical Aspects of Knowledge Management', count=38), Row(venue='Proceedings of the 19th annual symposium on Combinatorial Pattern Matching', count=28), Row(venue='Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 3', count=115), Row(venue='Lecture Notes In Computer Science; Vol. 5142', count=1), Row(venue='Proceedings of the 11th annual international ACM SIGIR conference on Research and development in information retrieval', count=45), Row(venue='Perspectives in artificial intelligence. Vol. 1: expert systems applications and technical foundations', count=10), Row(venue='Cross-Modal Analysis of Speech, Gestures, Gaze and Facial Expressions: COST Action 2102 International Conference Prague, Czech Republic, October 15-18, 2008 Revised Selected and Invited Papers', count=42), Row(venue='Logical frameworks', count=14), Row(venue='Proceedings of the annual ACM SIGUCCS symposium on The administration and management of small-college computing centers', count=13), Row(venue='Proceedings of the 18th International Conference on Systems Engineering', count=80), Row(venue='Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications', count=53), Row(venue='Proceedings of the 2nd International Conference on Theory and Practice of Electronic Governance', count=113), Row(venue=\"ACM SIGGRAPH 97 Visual Proceedings: The art and interdisciplinary programs of SIGGRAPH '97\", count=334), Row(venue='Proceedings of the 2nd IEEE International Conference on Engineering of Complex Computer Systems', count=88), Row(venue='Applied Stochastic Models in Business and Industry', count=85), Row(venue='WSEAS Transactions on Information Science and Applications', count=79), Row(venue='Proceedings of the 12th International Conference on Artificial Intelligence and Law', count=38), Row(venue='Proceeding of the 2007 conference on Emerging Artificial Intelligence Applications in Computer Engineering: Real Word AI Systems with Applications in eHealth, HCI, Information Retrieval and Pervasive Technologies', count=30), Row(venue='Proceedings of the 5th IEEE International Conference on Distributed Computing in Sensor Systems', count=26), Row(venue='Journal of the ACM (JACM)', count=647), Row(venue='Journal of Computers in Mathematics and Science Teaching', count=145), Row(venue='GI - 9. Jahrestagung', count=55), Row(venue='Proceedings of the 4th International Symposium on Formal Techniques in Real-Time and Fault-Tolerant Systems', count=29), Row(venue='Proceedings of the IFIP 17th World Computer Congress - TC13 Stream on Usability: Gaining a Competitive Edge', count=20), Row(venue='Selected Papers from the 4th European Conference on Artificial Evolution', count=14), Row(venue='Proceedings of the IFIP 17th World Computer Congress - TC10 Stream on Distributed and Parallel Embedded Systems: Design and Analysis of Distributed Embedded Systems', count=27), Row(venue='Information Resources Management Journal', count=45), Row(venue='Proceedings of the 25th international conference on Microelectronic engineering', count=15), Row(venue='Proceedings of the 3rd International Workshop on Meta-Programming in Logic', count=23), Row(venue='Proceedings of the 12th European Conference on Object-Oriented Programming', count=26)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(df_nodes_papers.groupby('venue').count().head(100))\n",
    "print(df_nodes_papers.filter(F.col('venue').isNull()).head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "928"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers.groupby('venue').count().filter('count > 100').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(venue='Computers in the Schools', count=351),\n Row(venue='Library Hi Tech', count=315),\n Row(venue='Proceedings of the Third International Conference on Medical Image Computing and Computer-Assisted Intervention', count=133),\n Row(venue='Proceedings of the 29th International Conference on Software Engineering Workshops', count=127),\n Row(venue='Proceedings of the 32nd IEEE Conference on Local Computer Networks', count=159)]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes_papers.groupby('venue').count().filter('count > 100').head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cant compute ground truth communities. Venue is actually a journal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}