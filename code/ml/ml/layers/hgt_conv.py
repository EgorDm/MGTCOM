from typing import Union, Dict, Optional, List

from tch_geometric.transforms.hgt_sampling import NAN_TIMEDELTA
from torch_geometric.typing import NodeType, EdgeType, Metadata

import math

import torch
from torch import Tensor
import torch.nn.functional as F
from torch.nn import Parameter, Embedding, Module
from torch_sparse import SparseTensor
from torch_geometric.nn.dense import Linear
from torch_geometric.utils import softmax
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.inits import glorot, ones, reset


def group(xs: List[Tensor], aggr: Optional[str]) -> Optional[Tensor]:
    if len(xs) == 0:
        return None
    elif aggr is None:
        return torch.stack(xs, dim=1)
    elif len(xs) == 1:
        return xs[0]
    else:
        out = torch.stack(xs, dim=0)
        out = getattr(torch, aggr)(out, dim=0)
        out = out[0] if isinstance(out, tuple) else out
        return out


# noinspection PyMethodOverriding
class HGTConv(MessagePassing):
    r"""The Heterogeneous Graph Transformer (HGT) operator from the
    `"Heterogeneous Graph Transformer" <https://arxiv.org/abs/2003.01332>`_
    paper.

    .. note::

        For an example of using HGT, see `examples/hetero/hgt_dblp.py
        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/
        hetero/hgt_dblp.py>`_.

    Args:
        in_channels (int or Dict[str, int]): Size of each input sample of every
            node type, or :obj:`-1` to derive the size from the first input(s)
            to the forward method.
        out_channels (int): Size of each output sample.
        metadata (Tuple[List[str], List[Tuple[str, str, str]]]): The metadata
            of the heterogeneous graph, *i.e.* its node and edge types given
            by a list of strings and a list of string triplets, respectively.
            See :meth:`torch_geometric.data.HeteroData.metadata` for more
            information.
        heads (int, optional): Number of multi-head-attentions.
            (default: :obj:`1`)
        group (string, optional): The aggregation scheme to use for grouping
            node embeddings generated by different relations.
            (:obj:`"sum"`, :obj:`"mean"`, :obj:`"min"`, :obj:`"max"`).
            (default: :obj:`"sum"`)
        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
    """

    def __init__(
            self,
            in_channels: Union[int, Dict[str, int]],
            out_channels: int,
            metadata: Metadata,
            heads: int = 1,
            group: str = "sum",
            use_RTE=False,
            **kwargs,
    ):
        super().__init__(aggr='add', node_dim=0, **kwargs)

        if not isinstance(in_channels, dict):
            in_channels = {node_type: in_channels for node_type in metadata[0]}

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.group = group
        self.use_RTE = use_RTE
        self.H, self.D = self.heads, self.out_channels // self.heads
        self.D_sqrt = math.sqrt(self.D)

        self.k_lin = torch.nn.ModuleDict()
        self.q_lin = torch.nn.ModuleDict()
        self.v_lin = torch.nn.ModuleDict()
        self.a_lin = torch.nn.ModuleDict()
        self.skip = torch.nn.ParameterDict()
        for node_type, in_channels in self.in_channels.items():
            self.k_lin[node_type] = Linear(in_channels, out_channels)
            self.q_lin[node_type] = Linear(in_channels, out_channels)
            self.v_lin[node_type] = Linear(in_channels, out_channels)
            self.a_lin[node_type] = Linear(out_channels, out_channels)
            self.skip[node_type] = Parameter(torch.Tensor(1))

        self.a_rel = torch.nn.ParameterDict()
        self.m_rel = torch.nn.ParameterDict()
        self.p_rel = torch.nn.ParameterDict()
        dim = out_channels // heads
        for edge_type in metadata[1]:
            edge_type = '__'.join(edge_type)
            self.a_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))
            self.m_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))
            self.p_rel[edge_type] = Parameter(torch.Tensor(heads))

        if self.use_RTE:
            self.emb = RelTemporalEncoding(in_channels)

        self.reset_parameters()

    def reset_parameters(self):
        reset(self.k_lin)
        reset(self.q_lin)
        reset(self.v_lin)
        reset(self.a_lin)
        ones(self.skip)
        ones(self.p_rel)
        glorot(self.a_rel)
        glorot(self.m_rel)

        if self.use_RTE:
            reset(self.emb)

    def forward(
            self,
            x_dict: Dict[NodeType, Tensor],
            edge_index_dict: Union[Dict[EdgeType, Tensor], Dict[EdgeType, SparseTensor]],  # Support both.
            edge_timedelta_dict: Optional[Dict[EdgeType, Tensor]] = None,
    ) -> Dict[NodeType, Optional[Tensor]]:
        r"""
        Args:
            x_dict (Dict[str, Tensor]): A dictionary holding input node
                features  for each individual node type.
            edge_index_dict: (Dict[str, Union[Tensor, SparseTensor]]): A
                dictionary holding graph connectivity information for each
                individual edge type, either as a :obj:`torch.LongTensor` of
                shape :obj:`[2, num_edges]` or a
                :obj:`torch_sparse.SparseTensor`.

        :rtype: :obj:`Dict[str, Optional[Tensor]]` - The ouput node embeddings
            for each node type.
            In case a node type does not receive any message, its output will
            be set to :obj:`None`.
        """

        q_dict, out_dict = {}, {}

        # Iterate over node-types:
        for node_type, x in x_dict.items():
            q_dict[node_type] = self.q_lin[node_type](x).view(-1, self.H, self.D)
            out_dict[node_type] = []

        # Iterate over edge-types:
        for edge_type, edge_index in edge_index_dict.items():
            j_type, _, i_type = edge_type

            edge_timedelta = edge_timedelta_dict[edge_type] if edge_timedelta_dict is not None else None
            x = x_dict[j_type]
            q = q_dict[i_type]

            out = self.propagate(
                edge_index, edge_timedelta=edge_timedelta, edge_type=edge_type,
                x=x, q=q, size=None
            )
            out_dict[i_type].append(out)

        # Iterate over node-types:
        for node_type, outs in out_dict.items():
            out = group(outs, self.group)

            if out is None:
                out_dict[node_type] = None
                continue

            out = self.a_lin[node_type](F.gelu(out))
            if out.size(-1) == x_dict[node_type].size(-1):
                alpha = self.skip[node_type].sigmoid()
                out = alpha * out + (1 - alpha) * x_dict[node_type]
            out_dict[node_type] = out

        return out_dict

    def message(
            self,
            x_j: Tensor, q_i: Tensor,
            edge_type: EdgeType, edge_timedelta: Optional[Tensor],
            index: Tensor, ptr: Optional[Tensor],
            size_i: Optional[int]
    ) -> Tensor:
        """
        j: source, i: target; <j, i>
        """
        j_type, _, i_type = edge_type
        edge_type = '__'.join(edge_type)

        # Temporal encoding
        if self.use_RTE:
            x_j = self.emb(x_j, edge_timedelta)

        # Attention
        a_rel = self.a_rel[edge_type]
        k_mat = self.k_lin[j_type](x_j).view(-1, self.H, self.D)
        k_mat = (k_mat.transpose(0, 1) @ a_rel).transpose(1, 0)
        att = (q_i * k_mat).sum(dim=-1) * self.p_rel[edge_type] / self.D_sqrt
        att_norm = softmax(att, index, ptr, size_i)

        # Message Passing
        m_rel = self.m_rel[edge_type]
        v_mat = self.v_lin[i_type](x_j).view(-1, self.H, self.D)
        msg = (v_mat.transpose(0, 1) @ m_rel).transpose(1, 0)

        # Apply attention
        out = msg * att_norm.view(-1, self.heads, 1)
        return out.reshape(-1, self.out_channels)

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}({self.out_channels}, '
                f'heads={self.heads})')


class RelTemporalEncoding(Module):
    """
    Implement the Temporal Encoding (Sinusoid) function.
    """

    def __init__(self, n_hid, max_len=240, dropout=0.2):
        super(RelTemporalEncoding, self).__init__()
        position = torch.arange(0., max_len - 1).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, n_hid, 2) * -(math.log(10000.0) / n_hid))

        emb = Embedding(max_len, n_hid)
        emb.weight.data[0, :] = 0
        emb.weight.data[1:, 0::2] = torch.sin(position * div_term) / math.sqrt(n_hid)
        emb.weight.data[1:, 1::2] = torch.cos(position * div_term) / math.sqrt(n_hid)
        emb.requires_grad = False
        self.emb = emb
        self.offset = int((max_len - 1) / 2)

        self.lin = Linear(n_hid, n_hid)

    def forward(self, x, t):
        t_idx = 1 + self.offset + t
        t_idx[t == NAN_TIMEDELTA] = 0
        return x + self.lin(self.emb(t_idx))
