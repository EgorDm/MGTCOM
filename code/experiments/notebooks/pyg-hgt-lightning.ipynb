{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from shared.schema import DatasetSchema, GraphSchema\n",
    "from shared.graph.loading import pd_from_entity_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET = DatasetSchema.load_schema('star-wars')\n",
    "schema = GraphSchema.from_dataset(DATASET)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "explicit_label = False\n",
    "explicit_timestamp = True\n",
    "unix_timestamp = True\n",
    "prefix_id = None\n",
    "include_properties = lambda cs: [c for c in cs if c.startswith('feat_') or c == 'name']\n",
    "\n",
    "nodes_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    ).set_index('id').drop(columns=['type']).sort_index()\n",
    "    for label, entity_schema in schema.nodes.items()\n",
    "}\n",
    "node_mappings_dfs = {\n",
    "    label: pd.Series(range(len(df)), index=df.index, name='nid')\n",
    "    for label, df in nodes_dfs.items()\n",
    "}\n",
    "\n",
    "edges_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    )\n",
    "        .reset_index()\n",
    "        .drop(columns=['type'])\n",
    "        .drop_duplicates(subset=['src', 'dst', 'timestamp'])\n",
    "        .join(node_mappings_dfs[entity_schema.source_type], on='src')\n",
    "        .drop(columns=['src'])\n",
    "        .rename(columns={'nid': 'src'})\n",
    "        .join(node_mappings_dfs[entity_schema.target_type], on='dst')\n",
    "        .drop(columns=['dst'])\n",
    "        .rename(columns={'nid': 'dst'})\n",
    "    for label, entity_schema in schema.edges.items()\n",
    "}\n",
    "\n",
    "cursor = 0\n",
    "for df in edges_dfs.values():\n",
    "    df.index += cursor\n",
    "    cursor += len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-07 15:19:37,300][git.cmd][DEBUG] Popen(['git', 'version'], cwd=/data/pella/projects/University/Thesis/Thesis/code/experiments/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "[2022-02-07 15:19:37,318][git.cmd][DEBUG] Popen(['git', 'version'], cwd=/data/pella/projects/University/Thesis/Thesis/code/experiments/notebooks, universal_newlines=False, shell=None, istream=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData, Data\n",
    "from torch_geometric.utils import negative_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "for ntype, ndf in nodes_dfs.items():\n",
    "    columns = [c for c in ndf.columns if c.startswith('feat_')]\n",
    "    data[ntype].x = torch.tensor(ndf[columns].values.astype(np.float32))\n",
    "    if 'timestamp' in ndf.columns:\n",
    "        data[ntype].timestamp = torch.tensor(ndf['timestamp'].values.astype(np.int32))\n",
    "\n",
    "for etype, edf in edges_dfs.items():\n",
    "    columns = [c for c in edf.columns if c.startswith('feat_')]\n",
    "    edge_schema = schema.edges[etype]\n",
    "    edge_type = (edge_schema.source_type, edge_schema.get_type(), edge_schema.target_type)\n",
    "    data[edge_type].edge_attr = torch.tensor(edf[columns].values.astype(np.float32))\n",
    "    data[edge_type].edge_index = torch.tensor(edf[['src', 'dst']].T.values.astype(np.int64))\n",
    "    if 'timestamp' in edf.columns:\n",
    "        data[edge_type].timestamp = torch.tensor(edf['timestamp'].values.astype(np.int32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001B[1mCharacter\u001B[0m={ x=[113, 32] },\n",
      "  \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n",
      "    edge_attr=[958, 0],\n",
      "    edge_index=[2, 958],\n",
      "    timestamp=[958]\n",
      "  },\n",
      "  \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n",
      "    edge_attr=[1120, 0],\n",
      "    edge_index=[2, 1120],\n",
      "    timestamp=[1120]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[24, 32],\n     batch_size=16\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[98, 0],\n     edge_index=[2, 98],\n     timestamp=[98],\n     edge_partitions=[98]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[81, 0],\n     edge_index=[2, 81],\n     timestamp=[81],\n     edge_partitions=[81]\n   }\n ),\n HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[24, 32],\n     batch_size=16\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[103, 0],\n     edge_index=[2, 103],\n     timestamp=[103],\n     edge_partitions=[103]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[104, 0],\n     edge_index=[2, 104],\n     timestamp=[104],\n     edge_partitions=[104]\n   }\n ),\n tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml.data import LinkSplitter, EdgeLoader\n",
    "\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: HeteroData,\n",
    "            node_type: str,\n",
    "            num_val=0.3,\n",
    "            num_test=0.0,\n",
    "            neg_sample_ratio=1.0,\n",
    "            num_samples=None,\n",
    "            batch_size=8,\n",
    "            num_workers=0,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.neg_sample_ratio = neg_sample_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = num_samples or [4] * 2\n",
    "        self.num_workers = num_workers\n",
    "        self.node_type = node_type\n",
    "\n",
    "        transform = LinkSplitter(\n",
    "            num_val=num_val,\n",
    "            num_test=num_test,\n",
    "            edge_types=data.edge_types,\n",
    "        )\n",
    "\n",
    "        self.train_data, self.val_data, self.test_data = transform(data)\n",
    "\n",
    "    def _get_edges_partition(self, data: HeteroData, partition: int) -> torch.Tensor:\n",
    "        pos_edge_index = {\n",
    "            edge_type: data[edge_type].edge_index[:, data[edge_type].edge_partitions == partition]\n",
    "            for edge_type in data.edge_types\n",
    "        }\n",
    "\n",
    "        neg_edge_index = {\n",
    "            edge_type: negative_sampling(\n",
    "                data[edge_type].edge_index,\n",
    "                num_neg_samples=int(pos_edge_index[edge_type].shape[1] * self.neg_sample_ratio)\n",
    "            )\n",
    "            for edge_type in data.edge_types\n",
    "        }\n",
    "\n",
    "        edge_index = {\n",
    "            edge_type: torch.cat([\n",
    "                torch.cat(\n",
    "                    [pos_edge_index[edge_type], torch.ones(1, pos_edge_index[edge_type].shape[1], dtype=torch.long)],\n",
    "                    dim=0),\n",
    "                torch.cat(\n",
    "                    [neg_edge_index[edge_type], torch.zeros(1, neg_edge_index[edge_type].shape[1], dtype=torch.long)],\n",
    "                    dim=0),\n",
    "            ], dim=1)\n",
    "            for edge_type in data.edge_types\n",
    "        }\n",
    "\n",
    "        return edge_index\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        edge_index = self._get_edges_partition(self.train_data, partition=0)\n",
    "        nodes = (self.node_type, torch.tensor(range(data[self.node_type].num_nodes)))\n",
    "\n",
    "        return EdgeLoader(\n",
    "            self.train_data,\n",
    "            num_samples=self.num_samples,\n",
    "            shuffle=True,\n",
    "            input_nodes=nodes,\n",
    "            input_edges=torch.cat([*edge_index.values()], dim=1).t(),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        edge_index = self._get_edges_partition(self.val_data, partition=1)\n",
    "        nodes = (self.node_type, torch.tensor(range(data[self.node_type].num_nodes)))\n",
    "\n",
    "        return EdgeLoader(\n",
    "            self.train_data,\n",
    "            num_samples=self.num_samples,\n",
    "            input_nodes=nodes,\n",
    "            input_edges=torch.cat([*edge_index.values()], dim=1).t(),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "data_module = DataModule(data, batch_size=16, num_samples=[4] * 2, num_workers=4, node_type='Character')\n",
    "# next(iter(data_module.train_dataloader()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class HGTModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(), num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels * 2, out_channels)\n",
    "\n",
    "    def forward_embed(self, x_dict, edge_index_dict):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict['Character']\n",
    "\n",
    "    def forward(self, larg, rarg):\n",
    "        lemb = self.forward_embed(*larg)\n",
    "        remb = self.forward_embed(*rarg)\n",
    "        emb = torch.cat([lemb, remb], dim=-1)\n",
    "\n",
    "        return self.lin(emb)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _step(self, batch, batch_idx):\n",
    "        batch_l, batch_r, label = batch\n",
    "        batch_size = batch_l['Character'].batch_size\n",
    "\n",
    "        out = self(\n",
    "            (batch_l.x_dict, batch_l.edge_index_dict),\n",
    "            (batch_r.x_dict, batch_r.edge_index_dict),\n",
    "        )[:batch_size]\n",
    "\n",
    "        loss = F.cross_entropy(out, label)\n",
    "\n",
    "        pred = out.argmax(dim=-1)\n",
    "        self.accuracy(pred, label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch, batch_idx)\n",
    "        self.log('train_acc', self.accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch, batch_idx)\n",
    "        self.log('val_acc', self.accuracy, prog_bar=True)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "model = HGTModel(hidden_channels=64, out_channels=4, num_heads=2, num_layers=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-07 13:44:56,792][py.warnings][WARNING] /data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "147d8b9e7a2d451cbf45072e52ac46e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f09653cfe2e41ba8397d5d285608b9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b375533b08f44c6a95972a7df8c8f442"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c4558abb8be493d8d7c1388ff2029d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28dc03b0dbfb43b08b0413bb74077894"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ce7ee8be150426886f9adb8ff082d18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c85be832d4764ef8bc31c2a31c8446e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a6757a6080c42d8bdd9e749968b5afd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1426825d7ce4036bfd49b639d0afe2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "301ac553a46f42a4a8c9cab86c627587"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e824db5a8eb74576995e2d7afebd274a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5868953f6164381b43c013f5eec945d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01a9e1c5c43944cabc4a742b59118bc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42a3857df326411995495d4dc246c9d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb76e826eec7415bb8d7f921014b5f81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "409d576c203849bba0b85cb260894944"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c42e4c278954c27b92b9d3fdffb8022"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67a338c09f294e2fb95d829142a9258a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75632c48e30447e494dc085bc69ab545"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ea687c8927d41bfb93e66c5f735f4da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aa0eeace395440a80870bd824ebefb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8b1256c70d64d98a68c96381fc1407d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89df45eb446b4fb68426949ae623ddae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b1b5ace674849d39aa1e72ff56f9c17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a43161d62be64156a4c3314b3bc6d59c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, callbacks=[\n",
    "    pl.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=5, verbose=True, mode=\"max\")\n",
    "])\n",
    "trainer.fit_loop.connect()\n",
    "trainer.fit(model, data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}