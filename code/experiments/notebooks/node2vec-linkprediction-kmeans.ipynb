{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-05 14:07:09,687][tensorflow][DEBUG] Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:07:10.463398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.471969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.472201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.472911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-05 14:07:10.473785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.473968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.474131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.945892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.946116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.946290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 14:07:10.946409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 717 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import UnsupervisedSampler, EdgeSplitter, BiasedRandomWalk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from shared.schema import DatasetSchema, GraphSchema\n",
    "from shared.graph.loading import pd_from_entity_schema\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-05 14:07:10,973][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.dataset.DatasetSchema'>, drop extra fields: True\n",
      "[2022-02-05 14:07:10,973][simple_parsing.helpers.serialization.decoding][DEBUG] name = name, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:10,974][simple_parsing.helpers.serialization.decoding][DEBUG] name = database, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:10,975][simple_parsing.helpers.serialization.decoding][DEBUG] name = description, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:10,975][simple_parsing.helpers.serialization.decoding][DEBUG] name = versions, field_type = typing.Dict[str, shared.schema.dataset.DatasetVersion]\n",
      "[2022-02-05 14:07:10,976][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Dict field: typing.Dict[str, shared.schema.dataset.DatasetVersion]\n",
      "[2022-02-05 14:07:10,977][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.dataset.DatasetVersion'>, drop extra fields: True\n",
      "[2022-02-05 14:07:10,977][simple_parsing.helpers.serialization.decoding][DEBUG] name = type, field_type = <enum 'DatasetVersionType'>\n",
      "[2022-02-05 14:07:10,978][simple_parsing.helpers.serialization.decoding][DEBUG] name = parameters, field_type = typing.Dict[str, typing.Any]\n",
      "[2022-02-05 14:07:10,979][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Dict field: typing.Dict[str, typing.Any]\n",
      "[2022-02-05 14:07:10,979][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding an Any type: typing.Any\n",
      "[2022-02-05 14:07:10,980][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.dataset.DatasetVersion'>, drop extra fields: True\n",
      "[2022-02-05 14:07:10,981][simple_parsing.helpers.serialization.decoding][DEBUG] name = type, field_type = <enum 'DatasetVersionType'>\n",
      "[2022-02-05 14:07:10,981][simple_parsing.helpers.serialization.decoding][DEBUG] name = parameters, field_type = typing.Dict[str, typing.Any]\n",
      "[2022-02-05 14:07:10,982][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.dataset.DatasetVersion'>, drop extra fields: True\n",
      "[2022-02-05 14:07:10,983][simple_parsing.helpers.serialization.decoding][DEBUG] name = type, field_type = <enum 'DatasetVersionType'>\n",
      "[2022-02-05 14:07:10,983][simple_parsing.helpers.serialization.decoding][DEBUG] name = parameters, field_type = typing.Dict[str, typing.Any]\n",
      "[2022-02-05 14:07:10,984][simple_parsing.helpers.serialization.decoding][DEBUG] name = tags, field_type = typing.List[str]\n",
      "[2022-02-05 14:07:10,984][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a List field: typing.List[str]\n",
      "[2022-02-05 14:07:11,004][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphSchema'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,005][simple_parsing.helpers.serialization.decoding][DEBUG] name = nodes, field_type = typing.Dict[str, shared.schema.graph.NodeSchema]\n",
      "[2022-02-05 14:07:11,006][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Dict field: typing.Dict[str, shared.schema.graph.NodeSchema]\n",
      "[2022-02-05 14:07:11,007][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.NodeSchema'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,008][simple_parsing.helpers.serialization.decoding][DEBUG] name = label, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,009][simple_parsing.helpers.serialization.decoding][DEBUG] name = properties, field_type = typing.Dict[str, shared.schema.graph.GraphProperty]\n",
      "[2022-02-05 14:07:11,010][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Dict field: typing.Dict[str, shared.schema.graph.GraphProperty]\n",
      "[2022-02-05 14:07:11,011][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,011][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,012][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,013][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,014][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,015][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,016][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,017][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,017][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,018][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,019][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,020][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,021][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,022][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,022][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,023][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,024][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,025][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,026][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,027][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,028][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,029][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,029][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,030][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,031][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,032][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,033][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,034][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,035][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,035][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,036][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,037][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,038][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,039][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,040][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,041][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,042][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,043][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,043][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,044][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,045][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,056][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,057][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,057][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,058][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,058][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,059][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,059][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,060][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,061][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,061][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,062][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,062][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,063][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,063][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,064][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,064][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,065][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,066][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,066][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,067][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,067][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,068][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,068][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,069][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,070][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,070][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,075][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,075][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,076][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,076][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,077][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,078][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,078][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,079][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,079][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,080][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,080][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,081][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,081][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,082][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,082][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,083][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,083][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,084][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,084][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,085][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,086][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,086][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,087][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,087][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,088][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,088][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,089][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,089][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,090][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,090][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,091][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,091][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,092][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,092][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,093][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,094][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,094][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,095][simple_parsing.helpers.serialization.decoding][DEBUG] name = edges, field_type = typing.Dict[str, shared.schema.graph.EdgeSchema]\n",
      "[2022-02-05 14:07:11,095][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Dict field: typing.Dict[str, shared.schema.graph.EdgeSchema]\n",
      "[2022-02-05 14:07:11,096][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.EdgeSchema'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,096][simple_parsing.helpers.serialization.decoding][DEBUG] name = properties, field_type = typing.Dict[str, shared.schema.graph.GraphProperty]\n",
      "[2022-02-05 14:07:11,097][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,097][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,098][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,099][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,099][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,100][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,100][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,101][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,101][simple_parsing.helpers.serialization.decoding][DEBUG] name = dynamic, field_type = typing.Optional[shared.schema.graph.DynamicConfig]\n",
      "[2022-02-05 14:07:11,103][simple_parsing.helpers.serialization.decoding][DEBUG] Decoding a Union field: typing.Optional[shared.schema.graph.DynamicConfig]\n",
      "[2022-02-05 14:07:11,105][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.DynamicConfig'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,106][simple_parsing.helpers.serialization.decoding][DEBUG] name = timestamp, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,106][simple_parsing.helpers.serialization.decoding][DEBUG] name = interaction, field_type = <class 'bool'>\n",
      "[2022-02-05 14:07:11,109][simple_parsing.helpers.serialization.decoding][DEBUG] name = source_type, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,109][simple_parsing.helpers.serialization.decoding][DEBUG] name = target_type, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,110][simple_parsing.helpers.serialization.decoding][DEBUG] name = directed, field_type = <class 'bool'>\n",
      "[2022-02-05 14:07:11,110][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.EdgeSchema'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,110][simple_parsing.helpers.serialization.decoding][DEBUG] name = properties, field_type = typing.Dict[str, shared.schema.graph.GraphProperty]\n",
      "[2022-02-05 14:07:11,111][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,111][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,111][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,112][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,112][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,112][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,113][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.GraphProperty'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,113][simple_parsing.helpers.serialization.decoding][DEBUG] name = dtype, field_type = <class 'shared.schema.graph.DType'>\n",
      "[2022-02-05 14:07:11,113][simple_parsing.helpers.serialization.decoding][DEBUG] name = dynamic, field_type = typing.Optional[shared.schema.graph.DynamicConfig]\n",
      "[2022-02-05 14:07:11,114][simple_parsing.helpers.serialization.serializable][DEBUG] from_dict for <class 'shared.schema.graph.DynamicConfig'>, drop extra fields: True\n",
      "[2022-02-05 14:07:11,114][simple_parsing.helpers.serialization.decoding][DEBUG] name = timestamp, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,114][simple_parsing.helpers.serialization.decoding][DEBUG] name = interaction, field_type = <class 'bool'>\n",
      "[2022-02-05 14:07:11,115][simple_parsing.helpers.serialization.decoding][DEBUG] name = source_type, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,115][simple_parsing.helpers.serialization.decoding][DEBUG] name = target_type, field_type = <class 'str'>\n",
      "[2022-02-05 14:07:11,115][simple_parsing.helpers.serialization.decoding][DEBUG] name = directed, field_type = <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "DATASET = DatasetSchema.load_schema('star-wars')\n",
    "schema = GraphSchema.from_dataset(DATASET)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "explicit_label = False\n",
    "explicit_timestamp = True\n",
    "unix_timestamp = True\n",
    "prefix_id = None\n",
    "include_properties = lambda cs: [c for c in cs if c.startswith('feat_') or c == 'name']\n",
    "\n",
    "nodes_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    ).set_index('id').drop(columns=['type']).sort_index()\n",
    "    for label, entity_schema in schema.nodes.items()\n",
    "}\n",
    "\n",
    "edges_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    ).reset_index().drop(columns=['type']).drop_duplicates(subset=['src', 'dst', 'timestamp'])\n",
    "    for label, entity_schema in schema.edges.items()\n",
    "}\n",
    "\n",
    "cursor = 0\n",
    "for df in edges_dfs.values():\n",
    "    df.index += cursor\n",
    "    cursor += len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 113, Edges: 2078\n",
      "\n",
      " Node types:\n",
      "  Character: [113]\n",
      "    Features: float32 vector, length 32\n",
      "    Edge types: Character-INTERACTIONS->Character, Character-MENTIONS->Character\n",
      "\n",
      " Edge types:\n",
      "    Character-MENTIONS->Character: [1120]\n",
      "        Weights: all 1 (default)\n",
      "        Features: float32 vector, length 2\n",
      "    Character-INTERACTIONS->Character: [958]\n",
      "        Weights: all 1 (default)\n",
      "        Features: float32 vector, length 2\n"
     ]
    }
   ],
   "source": [
    "graph = StellarGraph(\n",
    "    nodes={k: df.drop(columns=['name_']) for k, df in nodes_dfs.items()},\n",
    "    edges=edges_dfs,\n",
    "    source_column='src',\n",
    "    target_column='dst',\n",
    ")\n",
    "print(graph.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 103 positive and 103 negative edges. **\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 113, Edges: 1975\n",
      "\n",
      " Node types:\n",
      "  Character: [113]\n",
      "    Features: float32 vector, length 32\n",
      "    Edge types: Character-INTERACTIONS->Character, Character-MENTIONS->Character\n",
      "\n",
      " Edge types:\n",
      "    Character-MENTIONS->Character: [1062]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    Character-INTERACTIONS->Character: [913]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "edge_splitter_test = EdgeSplitter(graph)\n",
    "graph_sub_test, examples_test, labels_test = edge_splitter_test.train_test_split(\n",
    "    p=0.05, method=\"global\"\n",
    ")\n",
    "\n",
    "print(graph_sub_test.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 197 positive and 197 negative edges. **\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 113, Edges: 1778\n",
      "\n",
      " Node types:\n",
      "  Character: [113]\n",
      "    Features: float32 vector, length 32\n",
      "    Edge types: Character-INTERACTIONS->Character, Character-MENTIONS->Character\n",
      "\n",
      " Edge types:\n",
      "    Character-MENTIONS->Character: [952]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    Character-INTERACTIONS->Character: [826]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.75\n",
    "val_size = 0.25\n",
    "\n",
    "edge_splitter_train = EdgeSplitter(graph_sub_test)\n",
    "graph_train, examples, labels = edge_splitter_train.train_test_split(\n",
    "    p=0.1, method=\"global\"\n",
    ")\n",
    "\n",
    "(\n",
    "    examples_train,\n",
    "    examples_val,\n",
    "    labels_train,\n",
    "    labels_val,\n",
    ") = train_test_split(examples, labels, train_size=train_size, test_size=val_size)\n",
    "\n",
    "print(graph_train.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                Number of Examples  Hidden from Picked from  \\\nSplit                                                         \nTraining Set                   295  Train Graph  Test Graph   \nValidation Set                  99  Train Graph  Test Graph   \nTest set                       206   Test Graph  Full Graph   \n\n                                         Use  \nSplit                                         \nTraining Set       Train the Link Classifier  \nValidation Set  Validate the Link Classifier  \nTest set            Evaluate Link Classifier  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Number of Examples</th>\n      <th>Hidden from</th>\n      <th>Picked from</th>\n      <th>Use</th>\n    </tr>\n    <tr>\n      <th>Split</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Training Set</th>\n      <td>295</td>\n      <td>Train Graph</td>\n      <td>Test Graph</td>\n      <td>Train the Link Classifier</td>\n    </tr>\n    <tr>\n      <th>Validation Set</th>\n      <td>99</td>\n      <td>Train Graph</td>\n      <td>Test Graph</td>\n      <td>Validate the Link Classifier</td>\n    </tr>\n    <tr>\n      <th>Test set</th>\n      <td>206</td>\n      <td>Test Graph</td>\n      <td>Full Graph</td>\n      <td>Evaluate Link Classifier</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            \"Training Set\",\n",
    "            len(examples_train),\n",
    "            \"Train Graph\",\n",
    "            \"Test Graph\",\n",
    "            \"Train the Link Classifier\",\n",
    "        ),\n",
    "        (\n",
    "            \"Validation Set\",\n",
    "            len(examples_val),\n",
    "            \"Train Graph\",\n",
    "            \"Test Graph\",\n",
    "            \"Validate the Link Classifier\",\n",
    "        ),\n",
    "        (\n",
    "            \"Test set\",\n",
    "            len(examples_test),\n",
    "            \"Test Graph\",\n",
    "            \"Full Graph\",\n",
    "            \"Evaluate Link Classifier\",\n",
    "        ),\n",
    "    ],\n",
    "    columns=(\"Split\", \"Number of Examples\", \"Hidden from\", \"Picked from\", \"Use\"),\n",
    ").set_index(\"Split\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Attri2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from stellargraph.mapper import Attri2VecLinkGenerator\n",
    "from stellargraph.layer import Attri2Vec, link_classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epochs = 100\n",
    "walk_length = 5\n",
    "walk_number = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "unsupervised_samples = UnsupervisedSampler(\n",
    "    graph_train, nodes=list(graph_train.nodes()), length=walk_length, number_of_walks=walk_number\n",
    ")\n",
    "\n",
    "generator = Attri2VecLinkGenerator(graph_train, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [128]\n",
    "\n",
    "hinsage = Attri2Vec(\n",
    "    layer_sizes=layer_sizes, generator=generator, bias=False, normalize=None\n",
    ")\n",
    "\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[keras.metrics.binary_accuracy],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          4096        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_embedding (Embedding)    (None, 1, 128)       14464       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128)          0           output_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (LinkEmbedding)  (None, 1)            0           lambda[0][0]                     \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           link_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 18,560\n",
      "Trainable params: 18,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:07:11.866829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-05 14:07:12.835777: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-02-05 14:07:12.835831: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at matmul_op_impl.h:438 : Internal: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node model/dense/MatMul (defined at tmp/ipykernel_33478/2964640790.py:1) ]] [Op:__inference_train_function_777]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43munsupervised_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestore_best_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/keras/engine/training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:950\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    947\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    948\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;66;03m# stateless function.\u001B[39;00m\n\u001B[0;32m--> 950\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    952\u001B[0m   _, _, _, filtered_flat_args \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m    953\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn\u001B[38;5;241m.\u001B[39m_function_spec\u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    954\u001B[0m           \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   3037\u001B[0m   (graph_function,\n\u001B[1;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1966\u001B[0m     args,\n\u001B[1;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1968\u001B[0m     executing_eagerly)\n\u001B[1;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/data/pella/projects/University/Thesis/Thesis/code/env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInternalError\u001B[0m:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node model/dense/MatMul (defined at tmp/ipykernel_33478/2964640790.py:1) ]] [Op:__inference_train_function_777]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    generator.flow(unsupervised_samples),\n",
    "    validation_data=generator.flow(examples_val, labels_val),\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "        )\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract and cluster the embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_model = keras.Model(inputs=x_inp, outputs=x_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_node_list = graph.nodes()\n",
    "\n",
    "node_embeddings = embedding_model.predict(\n",
    "    generator.flow(list(zip(graph_node_list, graph_node_list)))\n",
    ")\n",
    "node_embeddings = node_embeddings[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(node_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shared.constants import BENCHMARKS_RESULTS\n",
    "\n",
    "save_path = BENCHMARKS_RESULTS.joinpath('analysis', 'node2vec-linkprediction-kmeans')\n",
    "save_path.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shared.graph import CommunityAssignment\n",
    "\n",
    "labeling = pd.Series(kmeans.labels_, index=graph_node_list, name=\"cid\")\n",
    "comlist = CommunityAssignment(labeling)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comlist.save_comlist(save_path.joinpath('schema.comlist'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets.scripts import export_to_visualization\n",
    "\n",
    "export_to_visualization.run(\n",
    "    export_to_visualization.Args(\n",
    "        dataset='star-wars',\n",
    "        version='base',\n",
    "        run_paths=[str(save_path)]\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Evaluation Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shared.graph import DataGraph\n",
    "from benchmarks.evaluation import get_metric_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = DataGraph.from_schema(schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = get_metric_list(ground_truth=False, overlapping=False)\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\n",
    "        'metric': metric_cls.metric_name(),\n",
    "        'value': metric_cls.calculate(G, comlist)\n",
    "    }\n",
    "    for metric_cls in metrics]\n",
    ")\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}