{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from shared.schema import DatasetSchema, GraphSchema\n",
    "from shared.graph.loading import pd_from_entity_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET = DatasetSchema.load_schema('star-wars')\n",
    "schema = GraphSchema.from_dataset(DATASET)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "explicit_label = False\n",
    "explicit_timestamp = True\n",
    "unix_timestamp = True\n",
    "prefix_id = None\n",
    "include_properties = lambda cs: [c for c in cs if c.startswith('feat_') or c == 'name']\n",
    "\n",
    "nodes_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    ).set_index('id').drop(columns=['type']).sort_index()\n",
    "    for label, entity_schema in schema.nodes.items()\n",
    "}\n",
    "node_mappings_dfs = {\n",
    "    label: pd.Series(range(len(df)), index=df.index, name='nid')\n",
    "    for label, df in nodes_dfs.items()\n",
    "}\n",
    "\n",
    "edges_dfs = {\n",
    "    label: pd_from_entity_schema(\n",
    "        entity_schema,\n",
    "        explicit_label=explicit_label,\n",
    "        explicit_timestamp=explicit_timestamp,\n",
    "        include_properties=include_properties,\n",
    "        unix_timestamp=unix_timestamp,\n",
    "        prefix_id=prefix_id,\n",
    "    )\n",
    "        .reset_index()\n",
    "        .drop(columns=['type'])\n",
    "        .drop_duplicates(subset=['src', 'dst', 'timestamp'])\n",
    "        .join(node_mappings_dfs[entity_schema.source_type], on='src')\n",
    "        .drop(columns=['src'])\n",
    "        .rename(columns={'nid': 'src'})\n",
    "        .join(node_mappings_dfs[entity_schema.target_type], on='dst')\n",
    "        .drop(columns=['dst'])\n",
    "        .rename(columns={'nid': 'dst'})\n",
    "    for label, entity_schema in schema.edges.items()\n",
    "}\n",
    "\n",
    "cursor = 0\n",
    "for df in edges_dfs.values():\n",
    "    df.index += cursor\n",
    "    cursor += len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData, Data\n",
    "from torch_geometric.utils import negative_sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "for ntype, ndf in nodes_dfs.items():\n",
    "    columns = [c for c in ndf.columns if c.startswith('feat_')]\n",
    "    data[ntype].x = torch.tensor(ndf[columns].values.astype(np.float32))\n",
    "    if 'timestamp' in ndf.columns:\n",
    "        data[ntype].timestamp = torch.tensor(ndf['timestamp'].values.astype(np.int32))\n",
    "\n",
    "for etype, edf in edges_dfs.items():\n",
    "    columns = [c for c in edf.columns if c.startswith('feat_')]\n",
    "    edge_schema = schema.edges[etype]\n",
    "    edge_type = (edge_schema.source_type, edge_schema.get_type(), edge_schema.target_type)\n",
    "    data[edge_type].edge_attr = torch.tensor(edf[columns].values.astype(np.float32))\n",
    "    data[edge_type].edge_index = torch.tensor(edf[['src', 'dst']].T.values.astype(np.int64))\n",
    "    if 'timestamp' in edf.columns:\n",
    "        data[edge_type].timestamp = torch.tensor(edf['timestamp'].values.astype(np.int32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001B[1mCharacter\u001B[0m={ x=[113, 32] },\n",
      "  \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n",
      "    edge_attr=[958, 0],\n",
      "    edge_index=[2, 958],\n",
      "    timestamp=[958]\n",
      "  },\n",
      "  \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n",
      "    edge_attr=[1120, 0],\n",
      "    edge_index=[2, 1120],\n",
      "    timestamp=[1120]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from ml.data import LinkSplitter\n",
    "\n",
    "transform = LinkSplitter(\n",
    "    num_val=0.3,\n",
    "    num_test=0.0,\n",
    "    edge_types=data.edge_types,\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from torch_geometric.loader import HGTLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from typing import List, Any, Tuple\n",
    "from torch_geometric.loader.base import BaseDataLoader\n",
    "\n",
    "class EdgeLoader(BaseDataLoader):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: HeteroData,\n",
    "            num_samples,\n",
    "            input_nodes,\n",
    "            input_edges,\n",
    "            **kwargs\n",
    "    ):\n",
    "        self.hgt_loader = HGTLoader(data, num_samples, input_nodes)\n",
    "\n",
    "        super(EdgeLoader, self).__init__(\n",
    "            input_edges.tolist(),\n",
    "            collate_fn=self.sample,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def sample(self, indices: List[Tuple[int, int, int]]):\n",
    "        idx_a, idx_b, labels = list(zip(*indices))\n",
    "        return self.hgt_loader.sample(idx_a), self.hgt_loader.sample(idx_b), torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "    def transform_fn(self, out: Any) -> HeteroData:\n",
    "        out_a, out_b, labels = out\n",
    "        return self.hgt_loader.transform_fn(out_a), self.hgt_loader.transform_fn(out_b), labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "(HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[16, 32],\n     batch_size=8\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[182, 0],\n     edge_index=[2, 182],\n     timestamp=[182]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[192, 0],\n     edge_index=[2, 192],\n     timestamp=[192]\n   }\n ),\n HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[16, 32],\n     batch_size=8\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[123, 0],\n     edge_index=[2, 123],\n     timestamp=[123]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[143, 0],\n     edge_index=[2, 143],\n     timestamp=[143]\n   }\n ),\n tensor([0, 1, 1, 1, 1, 1, 1, 0]))"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pos_edge_index = {\n",
    "    edge_type: train_data[edge_type].edge_index\n",
    "    for edge_type in train_data.edge_types\n",
    "}\n",
    "\n",
    "train_data_neg_edge_index = {\n",
    "    edge_type: negative_sampling(train_data[edge_type].edge_index, num_neg_samples=train_data_pos_edge_index[edge_type].shape[1])\n",
    "    for edge_type in train_data.edge_types \n",
    "}\n",
    "\n",
    "train_data_edge_index = {\n",
    "    edge_type: torch.cat([\n",
    "        torch.cat([train_data_pos_edge_index[edge_type], torch.ones(1, train_data_pos_edge_index[edge_type].shape[1], dtype=torch.long)], dim=0),\n",
    "        torch.cat([train_data_neg_edge_index[edge_type], torch.zeros(1, train_data_neg_edge_index[edge_type].shape[1], dtype=torch.long)], dim=0),\n",
    "    ], dim=1)\n",
    "    for edge_type in train_data.edge_types\n",
    "}\n",
    "\n",
    "train_loader = EdgeLoader(\n",
    "    data,\n",
    "    num_samples=[4] * 2,\n",
    "    shuffle=True,\n",
    "    input_nodes=('Character', torch.tensor(range(data['Character'].num_nodes))),\n",
    "    input_edges=torch.cat([\n",
    "        *train_data_edge_index.values()\n",
    "    ], dim=1).t(),\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "(HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[16, 32],\n     batch_size=8\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[109, 0],\n     edge_index=[2, 109],\n     timestamp=[109]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[76, 0],\n     edge_index=[2, 76],\n     timestamp=[76]\n   }\n ),\n HeteroData(\n   \u001B[1mCharacter\u001B[0m={\n     x=[16, 32],\n     batch_size=8\n   },\n   \u001B[1m(Character, INTERACTIONS, Character)\u001B[0m={\n     edge_attr=[110, 0],\n     edge_index=[2, 110],\n     timestamp=[110]\n   },\n   \u001B[1m(Character, MENTIONS, Character)\u001B[0m={\n     edge_attr=[86, 0],\n     edge_index=[2, 86],\n     timestamp=[86]\n   }\n ),\n tensor([1, 1, 1, 1, 0, 0, 1, 0]))"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_pos_edge_index = {\n",
    "    edge_type: val_data[edge_type].edge_index[:, val_data[edge_type].edge_partitions != 0]\n",
    "    for edge_type in val_data.edge_types\n",
    "}\n",
    "\n",
    "val_data_neg_edge_index = {\n",
    "    edge_type: negative_sampling(val_data[edge_type].edge_index, num_neg_samples=val_data_pos_edge_index[edge_type].shape[1])\n",
    "    for edge_type in val_data.edge_types\n",
    "}\n",
    "\n",
    "val_data_edge_index = {\n",
    "    edge_type: torch.cat([\n",
    "        torch.cat([val_data_pos_edge_index[edge_type], torch.ones(1, val_data_pos_edge_index[edge_type].shape[1], dtype=torch.long)], dim=0),\n",
    "        torch.cat([val_data_neg_edge_index[edge_type], torch.zeros(1, val_data_neg_edge_index[edge_type].shape[1], dtype=torch.long)], dim=0),\n",
    "    ], dim=1)\n",
    "    for edge_type in train_data.edge_types\n",
    "}\n",
    "\n",
    "val_loader = EdgeLoader(\n",
    "    data,\n",
    "    num_samples=[4] * 2,\n",
    "    shuffle=True,\n",
    "    input_nodes=('Character', torch.tensor(range(data['Character'].num_nodes))),\n",
    "    input_edges=torch.cat([\n",
    "        *val_data_edge_index.values()\n",
    "    ], dim=1).t(),\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(), num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels * 2, out_channels)\n",
    "\n",
    "    def forward_embed(self, x_dict, edge_index_dict):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict['Character']\n",
    "\n",
    "    def forward(self, larg, rarg):\n",
    "        lemb = self.forward_embed(*larg)\n",
    "        remb = self.forward_embed(*rarg)\n",
    "        emb = torch.cat([lemb, remb], dim=-1)\n",
    "\n",
    "        return self.lin(emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGT(\n",
      "  (lin_dict): ModuleDict(\n",
      "    (Character): Linear(-1, 64, bias=True)\n",
      "  )\n",
      "  (convs): ModuleList(\n",
      "    (0): HGTConv(64, heads=2)\n",
      "  )\n",
      "  (lin): Linear(128, 4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = HGT(hidden_channels=64, out_channels=4, num_heads=2, num_layers=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def init_params():\n",
    "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
    "    batch_l, batch_r, labels = next(iter(train_loader))\n",
    "    batch_l = batch_l.to(device)\n",
    "    batch_r = batch_r.to(device)\n",
    "    model(\n",
    "        (batch_l.x_dict, batch_l.edge_index_dict),\n",
    "        (batch_r.x_dict, batch_r.edge_index_dict),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch_l, batch_r, label in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = batch_l['Character'].batch_size\n",
    "        batch_l = batch_l.to(device)\n",
    "        batch_r = batch_r.to(device)\n",
    "\n",
    "        out = model(\n",
    "            (batch_l.x_dict, batch_l.edge_index_dict),\n",
    "            (batch_r.x_dict, batch_r.edge_index_dict),\n",
    "        )[:batch_size]\n",
    "\n",
    "        label = label.to(device)\n",
    "        loss = F.cross_entropy(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_examples = total_correct = 0\n",
    "    for batch_l, batch_r, label in tqdm(loader):\n",
    "        batch_size = batch_l['Character'].batch_size\n",
    "        batch_l = batch_l.to(device)\n",
    "        batch_r = batch_r.to(device)\n",
    "\n",
    "        out = model(\n",
    "            (batch_l.x_dict, batch_l.edge_index_dict),\n",
    "            (batch_r.x_dict, batch_r.edge_index_dict),\n",
    "        )[:batch_size]\n",
    "\n",
    "        pred = out.argmax(dim=-1)\n",
    "        label = label.to(device)\n",
    "\n",
    "        total_examples += batch_size\n",
    "        total_correct += int((pred == label).sum())\n",
    "\n",
    "    return total_correct / total_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "init_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:02<00:00, 60.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: untrained, Val Acc: 0.3716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 29.95it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.6664, Val Acc: 0.7255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 28.47it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 55.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 0.5569, Val Acc: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 31.80it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 60.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Loss: 0.5359, Val Acc: 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 28.27it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 58.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Loss: 0.5268, Val Acc: 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 29.40it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 58.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Loss: 0.5103, Val Acc: 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 31.20it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 56.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Loss: 0.5095, Val Acc: 0.7841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 30.10it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 59.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Loss: 0.5037, Val Acc: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 29.15it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 61.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Loss: 0.4938, Val Acc: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 31.52it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 62.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Loss: 0.5005, Val Acc: 0.7721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 28.57it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 60.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.4940, Val Acc: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 30.49it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 61.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.4896, Val Acc: 0.7873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 30.55it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.4869, Val Acc: 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:11<00:00, 30.48it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 61.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.4821, Val Acc: 0.7849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 29.19it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 59.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.4855, Val Acc: 0.7793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:13<00:00, 27.71it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 62.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.4814, Val Acc: 0.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:13<00:00, 27.54it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.4821, Val Acc: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 28.18it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.4793, Val Acc: 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:13<00:00, 26.70it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 60.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.4776, Val Acc: 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 28.78it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 62.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.4735, Val Acc: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [00:12<00:00, 29.32it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 56.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.4777, Val Acc: 0.7793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "val_acc = test(val_loader)\n",
    "print(f'Epoch: untrained, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    loss = train()\n",
    "    val_acc = test(val_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}