\chapter{Related Work} \label{sec:related_work}
%We summarize the differences of our work with some representative related work on graph embedding and community detection in \cref{tab:comparison_related_work}. Next, we detail the discussion of related work.

In this section, we provide an in-depth overview of related work and highlight important differences with our work by  mainly focusing on  graph embedding and community detection methods. A comparison of MGTCOM with the state-of-the-art is given in~\cref{tab:comparison_related_work}. 
As can be seen, MGTCOM is able to generate: (i) node, (ii) meta-topology, (iii) content, and (iv) temporal embeddings as well as (v) is able to infer the number of communities $(K)$. By contrast, state-of-the-art methods (such as GraphSAGE and ComE) are able to produce either two or three of the above. 
A commonality of all the methods is that they are all utilize topological features. 
Similarly, we focus on representation based community detection methods in contrast to traditional link-based methods.
We explain in detail these methods below. 
Throughout the paper we will use the terms network and graph interchangeably.

\input{figs/tab_sota_comparison.tex}

\section{Graph Embedding}
With the growing amount of rich graph data, efficient representation is highly demanded for retrieval and analytical purposes. 
Graph embedding focuses on the representation of nodes into low-dimensional vectors.
%
% Parallels to NLP
The graph representation field stems from computational linguistics, which relies heavily on the notion of \textit{distributional semantics}, stating that words occurring in the same context are semantically similar. By creating a parallel between words and nodes the linguistic approaches can be generalized to work in the context of graphs and vice versa.

% Implicit (context sampling-based)
Approaches such as DeepWalk \cite{perozziDeepWalkOnlineLearning2014}, LINE \cite{tangLINELargescaleInformation2015}, SDNE \cite{wangStructuralDeepNetwork2016} and Node2Vec \cite{groverNode2vecScalableFeature2016} utilize random walks as a means to generate context and adopt the Skip-gram \cite{mikolovDistributedRepresentationsWords2013} model to directly learn the node embeddings (\textit{shallow embedding} methods). 
By defining a trade-off between first- and higher-order proximity they provide a way to fine-tune the learned topological representations for the task at hand. 
Grover and Leskovec \cite{groverNode2vecScalableFeature2016} observe in their work that depth-first search sampling strategies (higher-order proximity) encourage network communities while breadth-first search (first-order proximity) encourages structural similarity as the local neighborhood is more thoroughly explored. 

% Explicit
On the other hand, matrix factorization-based approaches represent first-order proximity using an adjacency or Laplacian matrix. Consequently, they decompose the matrix in order to obtain node-based representation matrix ~\cite{brunaSpectralNetworksLocally2014}.
%Likewise, spectral methods can be used to approximate the Laplacian or similarity matrix of a network by means of matrix decomposition \cite{brunaSpectralNetworksLocally2014}.
As this process is quite expensive $O(n^{2.372})$, graph autoencoders (GAE) \cite{tianLearningDeepRepresentations2014, kipfVariationalGraphAutoEncoders2016} and graph convolutional networks (GCN) \cite{kipfSemiSupervisedClassificationGraph2017} are used instead.

% Various Problems 
Newer methods aim to solve various issues with current approaches involving scalability \cite{hamiltonInductiveRepresentationLearning2017, yingGraphConvolutionalNeural2018}, incorporation of node/edge features \cite{hamiltonInductiveRepresentationLearning2017, wuAuthor2VecFrameworkGenerating2020}, application to heterogeneous \cite{bordesTranslatingEmbeddingsModeling2013, dongMetapath2vecScalableRepresentation2017, huHeterogeneousGraphTransformer2020}, attributed \cite{chenCatGCNGraphConvolutional2021, wuTopologicalMachineLearning2020} and temporal \cite{nguyenContinuousTimeDynamicNetwork2018, dasguptaHyTEHyperplanebasedTemporally2018, wuSageDyNovelSampling2021} networks (see Table~\ref{tab:comparison_related_work} for comparison). In line with this, our proposed method (MGTCOM) is able to address all of the above issues.  

% Scale / Transitivity
\subsection{Scalability}
The authors of GraphSAGE (Hamilton et al. \cite{hamiltonInductiveRepresentationLearning2017}) argue that many graph embedding methods are \textit{transductive} and therefore have to be retrained upon the introduction of new or unseen nodes (nodes that are not part of the training data). 
Additionally, with the emergence of web-scale graphs containing billions of nodes, it is not possible to keep all node embeddings in memory \cite{yingGraphConvolutionalNeural2018}. 
Hence, in GraphSAGE, they introduce a local k-hop neighborhood sampling strategy and a GCN architecture that is able to infer node representations based on the sampled subgraph. 
A caveat of this approach is that the GCN architecture requires the presence of node features. While various workarounds exist to use zero or random vectors for missing features, this limits its application for various graph datasets.
In MGTCOM we overcome this issue by introducing auxiliary embeddings for nodes with missing features. By keeping auxiliary embeddings of most important nodes at hand, a primary embedding can be computed for each node within the graph.

% Heterogeneous networks
\subsection{Heterogeneous networks}
The above methods mainly work on homogeneous networks in which all nodes and edges belong to the same types. %there is only one node and one edge type. 
Often real-world data cannot be efficiently represented using homogeneous networks. 
Hence, to accurately represent real-world information heterogeneous networks are used. 
These networks involve \textit{meta-topological} information that characterizes various relationships between different types of nodes/entities \cite{yangHeterogeneousNetworkRepresentation2020}. 
Since most graph embedding methods are designed for homogeneous networks, extending them to incorporate heterogeneous networks is not trivial.

% Metapaths
One way to address meta-topological features is by using meta-path constrained random walks to capture semantic and structural relations between different node/entity types \cite{dongMetapath2vecScalableRepresentation2017, fuHIN2VecExploreMetapaths2017}. Meta-path describes a sequence of entity and relation types. For example, an "APA" meta-path would define a path between Author-Paper-Author node types. 
Derivative works introduce attention-based mechanisms to learn the importance of the meta-types \cite{wangHeterogeneousGraphAttention2019}.
While highly successful, the technique faces certain limitations, mainly that the construction of meta-paths requires extensive domain knowledge and that in highly heterogeneous networks such as knowledge graphs, the amount of meta-paths becomes unmanageable.

% Representation based
Other methods utilize a representation-based approach \cite{bordesTranslatingEmbeddingsModeling2013, wangKnowledgeGraphEmbedding2014} to explicitly capture meta-topological features by defining relations as translations between different node types. 
This approach is further utilized in GCN-based methods \cite{huHeterogeneousGraphTransformer2020, zhaoDeepAdversarialCompletion2020} to apply them in an inductive setting.
% 
Furthermore, in Hu et al. \cite{huHeterogeneousGraphTransformer2020} the authors improve the neighborhood sampling algorithm by introducing a type-based budget for unbiased sampling.

% Temporal networks
\subsection{Temporal networks}
Multimodal networks are dynamic and may evolve over time. %temporal semantic features. 
Temporal networks are a specialization of multimodal networks as they attach a start and end timestamp to each node and edge. Accordingly, graph representation methods should have the ability to capture this evolution.

Temporal graph embedding approaches are mainly split into two categories. 
Snapshot-based approaches operate by temporally splitting the graph into multiple snapshots or subgraphs and applying (modifying) existing graph embedding methods by temporally smoothing between the snapshots \cite{zhouDynamicNetworkEmbedding2019, goyalDyngraph2vecCapturingNetwork2020, mahdaviDynamicJointVariational2020, parejaEvolveGCNEvolvingGraph2020}.
The second category are the continuous temporal representation approaches which attempt to capture temporal information within the learned embeddings.
Generally, these methods look at the temporal progression of individual nodes rather than utilizing predefined snapshots.
The techniques vary; CTDNE introduces biased temporal random walks \cite{nguyenContinuousTimeDynamicNetwork2018}; SageDy introduces a neighborhood sampling technique to filter for temporal neighborhood \cite{wuSageDyNovelSampling2021}; BurstGraph captures node representation changes using a RNN \cite{zhaoLargeScaleEvolving2019}; HyTe \cite{dasguptaHyTEHyperplanebasedTemporally2018} modifies representation-based techniques to explicitly learn temporal information.


\section{Community Detection}
% Fundamentals
A community reveals patterns within its members that are different from those in other communities in a network.
There is an abundance of work concerning the finding of community structures by relying mainly on topological features \cite{fortunatoCommunityDetectionGraphs2010, xieOverlappingCommunityDetection2013}.
Despite this, the term \textit{community} does not have a universally accepted definition.
In their work Peel et al. \cite{peelGroundTruthMetadata2017} argue that community detection does not have a one size fits all solution and that definition and quality highly depend on the task at hand.
% Similarly they observe that the task of community detection is analogous to finding clusters in independent vector data.
Similarly, they observe that the task of community detection is analogous to finding clusters in document vectors.
Nevertheless a few common characteristics distinct community detection from tasks such as topic analysis and clustering including the involvement of topological information and the fact that the number of communities is not known a priori.

% More recent methods
Recent community detection methods focus on exploiting feature-rich information found in multimodal networks \cite{suComprehensiveSurveyCommunity2022}. 
% The focus has shifted from link-based methods towards deep learning methods which combine graph embedding methods with clustering algorithms to reliably find patterns in often noisy and/or incomplete graphs.
The focus has shifted from link-based methods towards deep learning methods which combine graph embedding methods with clustering algorithms (such as k-means or spectral clustering) \cite{tianLearningDeepRepresentations2014, kozdobaCommunityDetectionMeasure2015}. Similar methods are employed to learn find communities that take into account global context by utilizing graph autoencoders \cite{wangCommunityPreservingNetwork, caoIncorporatingNetworkStructure2018} or graph affiliation networks \cite{yangCommunityAffiliationGraphModel2012}.
%
% Community embeddings and Reinforcement methods
More advanced methods utilize multi-objective optimization by combining topological accuracy and cluster quality metrics during graph representation learning \cite{cavallariLearningCommunityEmbedding2017, rozemberczkiGEMSECGraphEmbedding2019, wangCombiningGraphConvolutional2021, zhangCommDGICommunityDetection2020}. Other methods focus on modifying \cite{jiaCommunityGANCommunityDetection2019} or augmenting \cite{kangCommunityReinforcementEffective2021} graph context sampling algorithms to reinforce communities within learned representations. 
% TODO: expand on cavallariLearningCommunityEmbedding2017

\subsection{Multimodal Methods}
% Homophily vs heterophily
Many methods rely on \textit{homophily} which refers to the assumption that "individuals" sharing similar patterns are more likely to be connected \cite{mcphersonBirdsFeatherHomophily2001}.
With the emergence of multimodal community detection methods \textit{heterophily} becomes equally important as similarity may not always be correlated with topological features \cite{zhuHomophilyGraphNeural}.
%
Some argue that consideration of link or content information alone is sufficient for identifying communities \cite{faniUserCommunityDetection2020}. Sparsity, noise, and irrelevant information may mislead traditional community detection or topic modeling algorithms.
However, both types of information may be of interest for analysis and may be valuable in overcoming noise in multimodal networks.

In line with this, various methods \cite{liuCommunityDetectionBased2014, sunRelationStrengthAwareClustering2012} modify Latent Dirichlet Allocation algorithm to incorporate attribute, topological and meta-topological information.
Cao et al. \cite{caoIncorporatingNetworkStructure2018} and Yang et al. \cite{yangGraphClusteringDynamic2017} utilize autoencoders to jointly optimize graph embeddings on content and topological information.
Fani et al. \cite{faniUserCommunityDetection2020} use topic models to construct a user interest histogram over a time axis, which in turn is used to learn temporal content-based node representations. 
% These representations are interpolated with topological representations and fed as link strength to the existing link-based community detection algorithm.
These representations are interpolated with topological representations, the similarity along edges is computed, and fed as edge weight to the existing link-based community detection algorithm (namely Louvain~\cite{blondelFastUnfoldingCommunities2008}).


\subsection{Heterogeneous Networks}
Meta-topological information is a valuable asset for the analysis of found communities. 
This information can be used in various ways to assist in community detection, for instance, by the representation of small node-specific ego-networks \cite{huangInformationFusionOriented2022} and learning the importance of network relations \cite{sunRelationStrengthAwareClustering2012}. 
%
Luo et al. \cite{luoDetectingCommunitiesHeterogeneous2021} propose CP-GNN which combines a heterogeneous graph transformer architecture with k-means clustering to find communities in content-rich heterogeneous graphs. Moreover, they devise a context-path-based k-hop neighborhood sampler to reinforce the discovery of community structures in topological data.  

\section{Clustering}
The task of clustering is to find groups of documents in a d-dimensional vector space based on a predefined similarity metric in an unsupervised manner \cite{minSurveyClusteringDeep2018}.
Many community detection algorithms rely on existing clustering algorithms such as k-means \cite{luoDetectingCommunitiesHeterogeneous2021, caoIncorporatingNetworkStructure2018, tianLearningDeepRepresentations2014, kozdobaCommunityDetectionMeasure2015, yangModularityBasedCommunity2016} and Gaussian Mixture Models (GMM) \cite{cavallariLearningCommunityEmbedding2017, choongLearningCommunityStructure2018}. Others employ end-to-end clustering techniques such as deep embedding clustering \cite{yangGraphClusteringDynamic2017} and clustering loss based parameter optimization \cite{rozemberczkiGEMSECGraphEmbedding2019, zhangCommDGICommunityDetection2020}.

As it is uncommon to know the number of clusters in community detection tasks \cite{fortunatoCommunityDetectionGraphs2010}, determining the optimal cluster count is often left to model selection which might become computationally expensive.
While various non-parametric clustering algorithms exist such as DBSCAN \cite{esterDensitybasedAlgorithmDiscovering1996}, OPTICS \cite{ankerstOPTICSOrderingPoints1999} and BIRCH \cite{zhangBIRCHEfficientData1996} they are not straightforward to incorporate into end-to-end applications.

Bayesian non-parametric methods such as Dirichlet Process Mixture (DPM) have had great results in clustering and community detection tasks where the number of communities is unknown \cite{zhuCombiningRandomWalks2016, zhuBayesianComplexNetwork2019, tonellatoBayesianNonparametricClustering2020}. 
As these models can evaluate the likelihood of a set of cluster parameters being drawn from a prior distribution, the task is transformed into a Markov Chain Monte Carlo (MCMC) sampling problem. Since there are prohibitively many possible parameter states, various hierarchical algorithms are proposed to explore the most promising states efficiently \cite{tehHierarchicalDirichletProcesses2006, changParallelSamplingDP2013a}.
Because these methods can be estimated using Expectation-Maximization (EM) algorithms, the previously introduced embedding methods can be utilized to learn representations and clusters in an end-to-end manner \cite{cavallariLearningCommunityEmbedding2017, ronenDeepDPMDeepClustering2022}.